{"cells":[{"cell_type":"markdown","metadata":{},"source":"ML/a\n====\n\n"},{"cell_type":"markdown","metadata":{},"source":["## @todo\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Shuffle the training data\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Batch normalization?\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Dropout\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Try recurrent cells\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Make the random split between the training and validation data deterministic based on a seed\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Use `Float32` instead of `UInt8` for the characters?\n\n"]},{"cell_type":"markdown","metadata":{},"source":["    : ┌ Warning: Slow fallback implementation invoked for conv!  You probably don't want this; check your datatypes.\n    : │   yT = Float32\n    : │   T1 = UInt8\n    : │   T2 = Float32\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Remotes\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Check the remote\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"daf087556f92\nProcess(`hostname`, ProcessExited(0))"}],"source":["run(`hostname`)"]},{"cell_type":"markdown","metadata":{},"source":["### Move data to the remote(s)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["    host=ubuntu@194.5.193.126\n    host_port=22\n\n    host=walle@51.178.215.202\n    host_port=2380\n\n    rsp-safe -e \"ssh -p ${host_port:-22}\" --rsync-path=\"mkdir -p ~/code/julia && rsync\" ~cod/julia/NightCommon ${host}:code/julia/\n    rsp-safe -e \"ssh -p ${host_port:-22}\" --exclude=models --rsync-path=\"mkdir -p ~/base/archives && rsync\" ~base/archives/nlp_data ${host}:base/archives/\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Get stuff from the remote\n\n"]},{"cell_type":"markdown","metadata":{},"source":["    tmuxnewsh2 save-j1 lo_s=10 loop rsp-safe -e \"ssh -p ${host_port:-22}\" ${host}:'logs/j1' ./\n\n"]},{"cell_type":"markdown","metadata":{},"source":["##### Models\n\n"]},{"cell_type":"markdown","metadata":{},"source":["    tmuxnewsh2 save-all lo_s=10 loop rsp-safe -e \"ssh -p ${host_port:-22}\" ${host}:'base/arch\n    ives/nlp_data/processBooks/' ./all/\n\n"]},{"cell_type":"markdown","metadata":{},"source":["###### Find the best model\n\n"]},{"cell_type":"markdown","metadata":{},"source":["    c ls -clt **/*(.) | perl -lne '/accu=(.*)/ && print $1' | sort\n\n"]},{"cell_type":"markdown","metadata":{},"source":["###### Copy\n\n"]},{"cell_type":"markdown","metadata":{},"source":["    rsp-safe -e \"ssh -p ${host_port:-22}\" ${host}: ./\n\n"]},{"cell_type":"markdown","metadata":{},"source":["##### To local\n\n"]},{"cell_type":"markdown","metadata":{},"source":["    rsp-safe 'zii@51.178.215.202:base/saved_models/elizium_vs_luminary_m1/all/models/21-11-10 19:09/230000_accu=0.899' .\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## GPU\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# import Pkg; Pkg.add(\"CUDA\")"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["GC.gc(true)\nCUDA.reclaim()"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Effective GPU memory usage: 69.73% (7.504 GiB/10.761 GiB)\nMemory pool usage: 6.642 GiB (6.750 GiB reserved)"}],"source":["CUDA.memory_status()"]},{"cell_type":"markdown","metadata":{},"source":["#### \\_\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"1×3 CuArray{Int64, 2, CUDA.Mem.DeviceBuffer}:\n 10  3  2"}],"source":["[10 3 2] |> gpu"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"1×3 CuArray{Int64, 2, CUDA.Mem.DeviceBuffer}:\n 10  3  2"}],"source":["[10 3 2] |> cu"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"1×3 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n 10.0  3.0  2.0"}],"source":["Float32.([10 3 2]) |> gpu"]},{"cell_type":"markdown","metadata":{},"source":["#### \\_\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Params([Float32[-0.111778125; 0.002819123; -0.027244896; -0.03988738]\n:\nFloat32[-0.18919002; -0.05827969; 0.12246067; -0.21493939]\n:\nFloat32[0.7942748; -1.4989135; -0.5318076; -0.7112862]\n:\n...\n:\nFloat32[-0.1343732; -0.008487504; -0.13199817; -0.009081438]\n:\nFloat32[0.41980788; -0.9344694; -0.5839063; 0.024473608]\n:\nFloat32[0.0014797748; -0.0027378402; -0.027659174; 0.0004863238], Float32[-0.12336355, -0.25500798, -0.004385097, -0.20307787, -1.6159056, -0.41346544, 0.0, -0.38553542, -0.005019192, 0.3411631  …  -1.3360305, -1.7169491, -0.16208945, 0.30585626, -0.07662875, 0.0, -0.0040730415, -0.008172875, -0.005298142, -0.13486442], Float32[0.0046841805 -0.02351334 … 0.017824527 0.0055555017; -0.0045686923 0.03180616 … -0.0575844 -0.015381001; … ; -0.016207157 0.018622335 … -0.019795312 -0.01859735; -0.114179954 0.03541677 … -0.035208307 -0.06850835], Float32[0.036304567, -0.19586259, -0.26909864, -0.26280588, -0.31083316, -0.7186801, -0.08919432, -0.20911779, 0.0048079244, -0.017520554  …  -0.86946017, -0.32969135, -0.037706837, 0.01641627, 0.08448448, -0.8033937, 0.06943873, -0.15353437, -0.03882099, -0.4388559], Float32[0.03218485 -0.16204661 … -0.014277367 0.028125435; 0.26154378 -0.800345 … 0.12894902 0.2691888; … ; -0.09592571 0.06082246 … 0.049979135 0.4438708; -0.028685609 -0.25797015 … -0.08898944 0.29308218], Float32[-0.025797812, -0.4099781, 0.3404507, -0.6801296, -0.42796856, 0.57648206, 0.2200871, 2.2506657, -0.34521192, 0.09023797  …  -1.7964157, -0.2455771, -0.70767885, 0.17814818, -1.926309, -2.1069493, -0.08664764, -1.6999221, -0.3778407, 1.0155528], Float32[0.04485587 0.1187261 … 0.088028684 -0.15526259; 0.071831286 -0.16534011 … -0.08978507 0.12799264; … ; -0.07809766 0.2991697 … -0.43194246 0.007871836; 0.06602923 0.52628297 … 0.03215004 -0.29033986], Float32[-0.34063843, -0.16484079, 0.4424414, -0.11640712, -0.9418747, -0.15433855, -0.93596625, -0.12772629, -0.7169618, -0.31299147  …  -0.50175637, -0.5899134, -4.7391863, -0.6534439, 0.0564369, 0.4552015, -0.32347828, -0.39680782, -0.5125247, -0.06212805], Float32[-0.014492278 -0.03157189 … 0.061014976 0.034709286], Float32[-0.5395494]])"}],"source":["ps"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# [goto error]\nMethodError: in(::Zygote.Params, ::Base.KeySet{Any, IdDict{Any, Any}}) is ambiguous. Candidates:\n  in(k, v::Base.KeySet{var\"#s77\", var\"#s76\"} where {var\"#s77\", var\"#s76\"<:IdDict}) in Base at iddict.jl:174\n  in(k, v::Base.KeySet) in Base at abstractdict.jl:69\n  in(x::Zygote.Params, args...; kwargs...) in Zygote at /home/walle/.julia/packages/MacroTools/PP9IQ/src/examples/forward.jl:17\nPossible fix, define\n  in(::Zygote.Params, ::Base.KeySet{var\"#s77\", T} where {var\"#s77\", T<:(IdDict{var\"#s77\", V} where V)})\n:\nStacktrace:\n [1] haskey(d::IdDict{Any, Any}, k::Zygote.Params)\n   @ Base ./abstractdict.jl:17\n [2] fmap(f::Flux.var\"#130#131\", x::Zygote.Params; exclude::typeof(Functors.isleaf), walk::typeof(Functors._default_walk), cache::IdDict{Any, Any})\n   @ Functors ~/.julia/packages/Functors/hIysk/src/functor.jl:120\n [3] fmap(f::Function, x::Zygote.Params)\n   @ Functors ~/.julia/packages/Functors/hIysk/src/functor.jl:120\n [4] cpu(x::Zygote.Params)\n   @ Flux ~/.julia/packages/Flux/BPPNj/src/functor.jl:115\n [5] top-level scope\n   @ In[35]:1\n [6] eval\n   @ ./boot.jl:360 [inlined]\n [7] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)\n   @ Base ./loading.jl:1116"}],"source":["cpu(ps)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Params([Float32[-0.111778125; 0.002819123; -0.027244896; -0.03988738]\n:\nFloat32[-0.18919002; -0.05827969; 0.12246067; -0.21493939]\n:\nFloat32[0.7942748; -1.4989135; -0.5318076; -0.7112862]\n:\n...\n:\nFloat32[-0.1343732; -0.008487504; -0.13199817; -0.009081438]\n:\nFloat32[0.41980788; -0.9344694; -0.5839063; 0.024473608]\n:\nFloat32[0.0014797748; -0.0027378402; -0.027659174; 0.0004863238], Float32[-0.12336355, -0.25500798, -0.004385097, -0.20307787, -1.6159056, -0.41346544, 0.0, -0.38553542, -0.005019192, 0.3411631  …  -1.3360305, -1.7169491, -0.16208945, 0.30585626, -0.07662875, 0.0, -0.0040730415, -0.008172875, -0.005298142, -0.13486442], Float32[0.0046841805 -0.02351334 … 0.017824527 0.0055555017; -0.0045686923 0.03180616 … -0.0575844 -0.015381001; … ; -0.016207157 0.018622335 … -0.019795312 -0.01859735; -0.114179954 0.03541677 … -0.035208307 -0.06850835], Float32[0.036304567, -0.19586259, -0.26909864, -0.26280588, -0.31083316, -0.7186801, -0.08919432, -0.20911779, 0.0048079244, -0.017520554  …  -0.86946017, -0.32969135, -0.037706837, 0.01641627, 0.08448448, -0.8033937, 0.06943873, -0.15353437, -0.03882099, -0.4388559], Float32[0.03218485 -0.16204661 … -0.014277367 0.028125435; 0.26154378 -0.800345 … 0.12894902 0.2691888; … ; -0.09592571 0.06082246 … 0.049979135 0.4438708; -0.028685609 -0.25797015 … -0.08898944 0.29308218], Float32[-0.025797812, -0.4099781, 0.3404507, -0.6801296, -0.42796856, 0.57648206, 0.2200871, 2.2506657, -0.34521192, 0.09023797  …  -1.7964157, -0.2455771, -0.70767885, 0.17814818, -1.926309, -2.1069493, -0.08664764, -1.6999221, -0.3778407, 1.0155528], Float32[0.04485587 0.1187261 … 0.088028684 -0.15526259; 0.071831286 -0.16534011 … -0.08978507 0.12799264; … ; -0.07809766 0.2991697 … -0.43194246 0.007871836; 0.06602923 0.52628297 … 0.03215004 -0.29033986], Float32[-0.34063843, -0.16484079, 0.4424414, -0.11640712, -0.9418747, -0.15433855, -0.93596625, -0.12772629, -0.7169618, -0.31299147  …  -0.50175637, -0.5899134, -4.7391863, -0.6534439, 0.0564369, 0.4552015, -0.32347828, -0.39680782, -0.5125247, -0.06212805], Float32[-0.014492278 -0.03157189 … 0.061014976 0.034709286], Float32[-0.5395494]])"}],"source":["Flux.params(model1)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# [goto error]\nMethodError: in(::Zygote.Params, ::Base.KeySet{Any, IdDict{Any, Any}}) is ambiguous. Candidates:\n  in(k, v::Base.KeySet{var\"#s77\", var\"#s76\"} where {var\"#s77\", var\"#s76\"<:IdDict}) in Base at iddict.jl:174\n  in(k, v::Base.KeySet) in Base at abstractdict.jl:69\n  in(x::Zygote.Params, args...; kwargs...) in Zygote at /home/walle/.julia/packages/MacroTools/PP9IQ/src/examples/forward.jl:17\nPossible fix, define\n  in(::Zygote.Params, ::Base.KeySet{var\"#s77\", T} where {var\"#s77\", T<:(IdDict{var\"#s77\", V} where V)})\n:\nStacktrace:\n [1] haskey(d::IdDict{Any, Any}, k::Zygote.Params)\n   @ Base ./abstractdict.jl:17\n [2] fmap(f::Flux.var\"#130#131\", x::Zygote.Params; exclude::typeof(Functors.isleaf), walk::typeof(Functors._default_walk), cache::IdDict{Any, Any})\n   @ Functors ~/.julia/packages/Functors/hIysk/src/functor.jl:120\n [3] fmap(f::Function, x::Zygote.Params)\n   @ Functors ~/.julia/packages/Functors/hIysk/src/functor.jl:120\n [4] cpu(x::Zygote.Params)\n   @ Flux ~/.julia/packages/Flux/BPPNj/src/functor.jl:115\n [5] top-level scope\n   @ In[38]:1\n [6] eval\n   @ ./boot.jl:360 [inlined]\n [7] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)\n   @ Base ./loading.jl:1116"}],"source":["cpu(Flux.params(model1))"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Params([Float32[-0.111778125; 0.002819123; -0.027244896; -0.03988738]\n:\nFloat32[-0.18919002; -0.05827969; 0.12246067; -0.21493939]\n:\nFloat32[0.7942748; -1.4989135; -0.5318076; -0.7112862]\n:\n...\n:\nFloat32[-0.1343732; -0.008487504; -0.13199817; -0.009081438]\n:\nFloat32[0.41980788; -0.9344694; -0.5839063; 0.024473608]\n:\nFloat32[0.0014797748; -0.0027378402; -0.027659174; 0.0004863238], Float32[-0.12336355, -0.25500798, -0.004385097, -0.20307787, -1.6159056, -0.41346544, 0.0, -0.38553542, -0.005019192, 0.3411631  …  -1.3360305, -1.7169491, -0.16208945, 0.30585626, -0.07662875, 0.0, -0.0040730415, -0.008172875, -0.005298142, -0.13486442], Float32[0.0046841805 -0.02351334 … 0.017824527 0.0055555017; -0.0045686923 0.03180616 … -0.0575844 -0.015381001; … ; -0.016207157 0.018622335 … -0.019795312 -0.01859735; -0.114179954 0.03541677 … -0.035208307 -0.06850835], Float32[0.036304567, -0.19586259, -0.26909864, -0.26280588, -0.31083316, -0.7186801, -0.08919432, -0.20911779, 0.0048079244, -0.017520554  …  -0.86946017, -0.32969135, -0.037706837, 0.01641627, 0.08448448, -0.8033937, 0.06943873, -0.15353437, -0.03882099, -0.4388559], Float32[0.03218485 -0.16204661 … -0.014277367 0.028125435; 0.26154378 -0.800345 … 0.12894902 0.2691888; … ; -0.09592571 0.06082246 … 0.049979135 0.4438708; -0.028685609 -0.25797015 … -0.08898944 0.29308218], Float32[-0.025797812, -0.4099781, 0.3404507, -0.6801296, -0.42796856, 0.57648206, 0.2200871, 2.2506657, -0.34521192, 0.09023797  …  -1.7964157, -0.2455771, -0.70767885, 0.17814818, -1.926309, -2.1069493, -0.08664764, -1.6999221, -0.3778407, 1.0155528], Float32[0.04485587 0.1187261 … 0.088028684 -0.15526259; 0.071831286 -0.16534011 … -0.08978507 0.12799264; … ; -0.07809766 0.2991697 … -0.43194246 0.007871836; 0.06602923 0.52628297 … 0.03215004 -0.29033986], Float32[-0.34063843, -0.16484079, 0.4424414, -0.11640712, -0.9418747, -0.15433855, -0.93596625, -0.12772629, -0.7169618, -0.31299147  …  -0.50175637, -0.5899134, -4.7391863, -0.6534439, 0.0564369, 0.4552015, -0.32347828, -0.39680782, -0.5125247, -0.06212805], Float32[-0.014492278 -0.03157189 … 0.061014976 0.034709286], Float32[-0.5395494]])"}],"source":["Flux.params(cpu(model1))"]},{"cell_type":"markdown","metadata":{},"source":["#### @broken Use `IdDict` instead:PROPERTIES:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# [goto error]\nScalar indexing is disallowed.\nInvocation of getindex resulted in scalar indexing of a GPU array.\nThis is typically caused by calling an iterating implementation of a method.\nSuch implementations *do not* execute on the GPU, but very slowly on the CPU,\nand therefore are only permitted from the REPL for prototyping purposes.\nIf you did intend to index this array, annotate the caller with @allowscalar.\n:\nStacktrace:\n  [1] error(s::String)\n    @ Base ./error.jl:33\n  [2] assertscalar(op::String)\n    @ GPUArrays ~/.julia/packages/GPUArrays/3sW6s/src/host/indexing.jl:53\n  [3] getindex\n    @ ~/.julia/packages/GPUArrays/3sW6s/src/host/indexing.jl:86 [inlined]\n  [4] getindex\n    @ ./subarray.jl:309 [inlined]\n  [5] hash(A::SubArray{Float32, 1, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}, Tuple{UnitRange{Int64}}, true}, h::UInt64)\n    @ Base ./abstractarray.jl:2432\n  [6] hash\n    @ ./pair.jl:52 [inlined]\n  [7] hash(A::Vector{SubArray{Float32, 1, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}, Tuple{UnitRange{Int64}}, true}}, h::UInt64)\n    @ Base ./abstractarray.jl:2433\n  [8] hash(x::Vector{SubArray{Float32, 1, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}, Tuple{UnitRange{Int64}}, true}})\n    @ Base ./hashing.jl:18\n  [9] hash(a::Dict{Symbol, Any}, h::UInt64)\n    @ Base ./abstractdict.jl:489\n [10] hash\n    @ ./hashing.jl:18 [inlined]\n [11] hashindex\n    @ ./dict.jl:169 [inlined]\n [12] ht_keyindex2!(h::Dict{Dict{Symbol, Any}, Int64}, key::Dict{Symbol, Any})\n    @ Base ./dict.jl:310\n [13] setindex!(h::Dict{Dict{Symbol, Any}, Int64}, v0::Int64, key::Dict{Symbol, Any})\n    @ Base ./dict.jl:383\n [14] top-level scope\n    @ In[52]:2\n [15] eval\n    @ ./boot.jl:360 [inlined]\n [16] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)\n    @ Base ./loading.jl:1116"}],"source":["is = Dict{Book, Int}()\nis[elizium] = 2"]},{"cell_type":"markdown","metadata":{},"source":["## Bootstrap\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# using Revise # @redundant\nconst LOCAL_PACKAGES = expanduser(\"~/code/julia/\")\npush!(LOAD_PATH, LOCAL_PACKAGES)\n\nusing NightCommon"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# [goto error]\nArgumentError: Package CUDA not found in current path:\n- Run `import Pkg; Pkg.add(\"CUDA\")` to install the CUDA package.\n:\n:\nStacktrace:\n [1] require(into::Module, mod::Symbol)\n   @ Base ./loading.jl:871\n [2] eval\n   @ ./boot.jl:360 [inlined]\n [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)\n   @ Base ./loading.jl:1094"}],"source":["using Random\nusing Base.Iterators\nusing LinearAlgebra\nusing Distributions\nusing Flux\nusing UnicodePlots\nimport Zygote\nimport Dates\nimport BSON\nusing CUDA\nCUDA.allowscalar(false)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"eclog (generic function with 1 method)"}],"source":["logdir = \"$(homedir())/logs/\"\nensureDir(logdir)\nlog_file = open(\"$(logdir)/j1\",\"a+\")\nfunction eclog(str)\n    println(log_file, str)\n    flush(log_file)\nend"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["eclog(\"\\n----------------------\\nStarted\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["## Hello Flux\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Synthesis\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"ground_truth (generic function with 1 method)"}],"source":["W_truth = [1 2 3.1 4 5;\n            5 4 300 2.9 1]\nb_truth = [-100.78; -2.3]\nground_truth(x) = W_truth*x .+ b_truth"]},{"cell_type":"markdown","metadata":{},"source":["### Training data\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"100000-element Vector{Vector{Float64}}:\n [100.36979583608108, 108.17272057468041, 108.13216857593622, 102.55596012750429, 109.57065453997049]\n [100.44472492413394, 108.43515993819202, 101.55092748751085, 107.11292635602152, 101.79524735256447]\n [109.00658525869122, 101.58210206368936, 105.51660384612553, 104.85685363518186, 105.71371287219621]\n [103.38486855513372, 106.23320922228451, 105.19031888773029, 108.42068483761616, 106.11467018171516]\n [100.40140602704624, 101.37256451640205, 102.52920830317863, 105.23863831522823, 104.83088460568285]\n [104.80846091334296, 109.27158423640607, 101.52866219119274, 104.77331164184251, 109.79490005189709]\n [102.56373548911344, 101.151263919452, 101.41860045778343, 106.95126662881235, 108.48505788579226]\n [101.20496406962556, 103.60817175638607, 103.69585673727094, 104.02418314236131, 107.91481286996839]\n [107.7867213587923, 100.16638353637622, 100.35141373810708, 102.46760181769352, 101.38451658839273]\n [103.19874403546231, 102.63568583998585, 108.09753420836485, 100.24899867337709, 103.82380950581822]\n [104.13298867582984, 101.14242483570106, 107.78259278397968, 105.97879713656089, 101.74337654001522]\n [109.24940620372966, 107.31769036135181, 106.60242441026423, 101.76931114450122, 103.36013588784681]\n [101.88180568480068, 109.14786765753644, 103.04037298174951, 105.64675710710799, 100.9450805031335]\n ⋮\n [109.94447818861076, 107.09827056798805, 103.77614264679953, 109.01375840291946, 107.52853204135349]\n [107.36558112948407, 101.00581096874745, 107.22778201804897, 101.24518101088728, 107.41083732917485]\n [101.27711770559824, 108.90314300550493, 101.26908359163107, 106.11375689379527, 104.91302013168084]\n [102.65765726181017, 100.2741528047537, 103.29590706522308, 109.87161477587163, 101.18621849888797]\n [106.94522472801248, 106.18849924905513, 106.43574990026252, 101.76302028623583, 103.44737444435215]\n [106.10642522346733, 104.52425393677184, 101.98878194967945, 107.59272618260448, 101.04000773405382]\n [104.50968872888951, 104.587626328234, 106.17164465478386, 101.75536086491522, 101.08851089598623]\n [106.18546137244768, 104.12298899367362, 100.25319859168985, 107.65588578488328, 105.24238314527345]\n [105.48988440772116, 108.45673061525132, 108.81394685548135, 106.63472001009077, 107.8847675126022]\n [106.30806672811083, 108.08169022780484, 106.23400345085997, 108.2345596802688, 101.45577117772316]\n [100.73556967603075, 100.95680374945198, 102.03643016951354, 108.26393448927217, 104.09133922175752]\n [106.96704452177362, 104.6505635196802, 109.36190747398466, 100.43728062981657, 108.47428791160505]"}],"source":["xs_train = [(rand(Float64,5)*10 .+ 100) for i in 1:100_000]"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"100000-element Vector{Vector{Float64}}:\n [1509.4908685790447, 33778.97067262285]\n [1469.6211967501786, 31811.706692890388]\n [1486.5306955089723, 33013.89232426207]\n [1505.8763650121678, 32917.8887159962]\n [1466.2755911236095, 32074.877144340353]\n [1506.046785276518, 31831.70647463568]\n [1489.0449477527452, 31759.922559892806]\n [1485.0073539132018, 32436.60406649058]\n [1435.795246318564, 31441.288875989052]\n [1462.963445642635, 33748.5562942912]\n [1473.0044565127232, 33667.65712376475]\n [1477.6231879593809, 33353.05484326523]\n [1466.3133666095014, 32263.20325021832]\n ⋮\n [1519.3740578988936, 32532.482028641873]\n [1483.6234664182145, 33508.613084596494]\n [1482.0110160685174, 31733.57925731069]\n [1468.1221131769246, 32321.23512803118]\n [1473.287784814114, 33287.34822054001]\n [1466.129435911688, 31956.222287420984]\n [1454.5671691518387, 33187.15389698428]\n [1481.3119664037233, 31438.731098602915]\n [1525.6184776258503, 34021.03552173618]\n [1491.971879484515, 33247.437112798674]\n [1472.6724468204152, 31934.494673164743]\n [1499.4709234539773, 34159.453716272714]"}],"source":["ys_train = [ground_truth(x) + rand(2) for x in xs_train]"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"|  9.731267315697135 |  9.958680324172958 | 5.107991701340638 | 8.030787679260214 | 8.84921805213325 |\n| 20.803722553240227 | 1650.4759777536717 |                   |                   |                  |"}],"source":["# train_data = zip(xs_train, ys_train)\ntrain_data = zip(x_train, y_train)\nfirst(train_data)"]},{"cell_type":"markdown","metadata":{},"source":["### Model\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["function ps_init()\n    global W = rand(2,5)\n    global b = rand(2,1)\n\n    global ps = Flux.params(W, b)\nend\n\nps_init()"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"model (generic function with 1 method)"}],"source":["model(x) = W*x + b"]},{"cell_type":"markdown","metadata":{},"source":["### Loss and optimizer\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"loss (generic function with 2 methods)"}],"source":["function loss(x, target, pred)\n    se = (pred .- target).^2\n    res = sum(se)\n\n    # println(\"se: $se, loss: $res\")\n    return res\nend"]},{"cell_type":"markdown","metadata":{},"source":["### Training\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"2×1 Matrix{Float64}:\n 0.21621735587862734\n 0.6929369880227094"}],"source":["ps_init()\nlosses = Float64[]\nmin_loss = Inf\nbest_W = W\nbest_b = b"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"---------------\nx =>\t[9.745641720016033, 9.10097490619058, 9.880925610044365, 8.309731956730428, 7.989954647936419]\npred =>\t[18.044926138820614; 2866.787490630857]\ntarget =>\t[30.80810046870502, 3079.278856287415]\ncurrent_loss =>\t45315.47909756394\ngs[ps[1]] =>\t[-248.7706484583183 -232.3146585992275 -252.22395220323133 -212.11711519672383 -203.95436811896542; -4141.729436571462 -3867.757173244997 -4199.222753658366 -3531.4925834511764 -3395.592749347941]\ngs[ps[2]] =>\t[-25.526348659768814; -424.98273131311544]\nps[2] =>\t[-0.059457474882017344; 134.11003329266492]\n---------------\nx =>\t[9.982730581522594, 6.88840451423814, 7.913588415335067, 9.602511046964946, 5.761185136026533]\npred =>\t[7.240336198184552; 2471.1289315630265]\ntarget =>\t[14.852228708663867, 2482.8474003988827]\ncurrent_loss =>\t195.26341944802238\ngs[ps[1]] =>\t[-151.9749442952493 -104.8675894621624 -120.47476877940973 -146.1865638403747 -87.70704397681024; -233.96463443264088 -161.44310725774062 -185.47027844979212 -225.05345289964583 -135.02453694824897]\ngs[ps[2]] =>\t[-15.22378502095863; -23.436937671712258]\nps[2] =>\t[-3.119628166105348; 148.13484811329025]\n---------------\nx =>\t[6.292123889448201, 5.572606910644091, 5.764044712518562, 9.971191443949667, 9.592466647407212]\npred =>\t[17.00450526428546; 1810.6994431358282]\ntarget =>\t[22.624574283112857, 1819.2064748032285]\ncurrent_loss =>\t103.95476356653455\ngs[ps[1]] =>\t[-70.72434106742315 -62.636870905228626 -64.78865822392288 -112.07756822987669 -107.82064923845677; -107.0545943654832 -94.81268691764573 -98.06982180341298 -169.6504827507809 -163.2068350759481]\ngs[ps[2]] =>\t[-11.240138037654795; -17.01406333480054]\nps[2] =>\t[-18.146868548552415; 124.98303659079237]\n---------------\nx =>\t[7.40065335859841, 6.656590616380632, 8.518018686250146, 7.124480350724576, 5.316820485034204]\npred =>\t[6.816690612570522; 2651.2168470154475]\ntarget =>\t[1.4111392274886356, 2642.6873703588367]\ncurrent_loss =>\t101.97195781242871\ngs[ps[1]] =>\t[80.0092240261651 71.96508525259883 92.08917541522574 77.02348925569582 57.480692674216776; 126.24740013166644 113.55446855006578 145.3084830898899 121.53617768397474 90.69939242897837]\ngs[ps[2]] =>\t[10.811102770163773; 17.058953313221537]\nps[2] =>\t[-30.14924415492992; 106.49490946062708]\n---------------\nx =>\t[9.348874769609289, 9.48132295040376, 6.346399846275067, 7.739239533252926, 7.722334184745371]\npred =>\t[4.518774679678664; 1997.8313763652184]\ntarget =>\t[16.52393366597871, 2016.4390206129237]\ncurrent_loss =>\t490.3682667355033\ngs[ps[1]] =>\t[-224.46945590433745 -227.6495788401051 -152.37907829032468 -185.82160205951988 -185.41569926641586; -347.9210716584762 -352.85016891743476 -236.18310118635694 -288.01803196509553 -287.3888945432714]\ngs[ps[2]] =>\t[-24.01031797260009; -37.21528849541073]\nps[2] =>\t[-36.98949317203729; 95.9584190985206]\n---------------\nx =>\t[6.040859718406763, 7.804729929473719, 5.708607145066713, 9.549115318058782, 6.271290774830542]\npred =>\t[12.441603022679082; 1812.1985042693975]\ntarget =>\t[8.270622148975587, 1805.5824770806391]\ncurrent_loss =>\t61.1688972111905\ngs[ps[1]] =>\t[50.39262069240098 65.10675852051223 47.62098243512075 79.6583547048245 52.314867750502735; 79.93298428090887 103.27261082862881 75.53660016340346 126.35441314573205 82.98206054977696]\ngs[ps[2]] =>\t[8.341961747406991; 13.23205437751676]\nps[2] =>\t[-41.145433308806616; 89.55515056429233]\n---------------\nx =>\t[9.50184162759799, 8.538448279152352, 5.937053605566673, 7.83533876155829, 5.359575526197977]\npred =>\t[6.6231562766045045; 1894.979568704417]\ntarget =>\t[1.9817384247489067, 1888.8402211307045]\ncurrent_loss =>\t59.23434830637321\ngs[ps[1]] =>\t[88.20403471167593 79.26101254000687 55.1126931846016 72.73416240646557 49.75205905132731; 116.67021668438801 104.84100345176707 72.89927129667342 96.20773602997654 65.80859400578473]\ngs[ps[2]] =>\t[9.282835703711196; 12.278695147424969]\nps[2] =>\t[-45.68203870585836; 82.56504696631826]\n---------------\nx =>\t[9.187257892352852, 8.66032735591489, 9.312711881756764, 7.295707589427934, 5.650836692076445]\npred =>\t[9.572642495432127; 2895.0255629696167]\ntarget =>\t[11.825361270220537, 2898.8434301618286]\ncurrent_loss =>\t19.650851775652217\ngs[ps[1]] =>\t[-41.392616685852516 -39.01856406096626 -41.95784180045712 -32.87035492414119 -25.459491819007674; -70.15146098720773 -66.12795937192548 -71.10939432776232 -55.70808529929665 -43.14828803045183]\ngs[ps[2]] =>\t[-4.505437549576818; -7.635734384423813]\nps[2] =>\t[-46.79707835221256; 80.84695862939975]\n---------------\nx =>\t[7.568334209639169, 9.626727194587396, 5.279340383568343, 5.694535246625735, 9.465431609541453]\npred =>\t[12.475318214882762; 1683.6710095330102]\ntarget =>\t[12.575350580303429, 1683.8494785428566]\ncurrent_loss =>\t0.04185766160719646\ngs[ps[1]] =>\t[-1.5141567465687167 -1.9259685850680726 -1.0562098128583828 -1.1392756613826642 -1.8936990272599605; -2.701426225161379 -3.4361449409582145 -1.8843973017947635 -2.032596134001065 -3.378572414246735]\ngs[ps[2]] =>\t[-0.20006473084133347; -0.3569380196927341]\nps[2] =>\t[-54.86276071130685; 68.42414570915939]\n---------------\nx =>\t[6.587916984199005, 8.688125009052486, 5.53021936320296, 7.3362137696440275, 8.66437854019398]\npred =>\t[15.634249169187086; 1758.3022137908981]\ntarget =>\t[12.773398483277054, 1754.340911545644]\ncurrent_loss =>\t23.87638212532665\ngs[ps[1]] =>\t[37.69409364592814 49.71085678283982 31.642263716904257 41.975624389737476 49.57498657939622; 52.19346068210957 68.83257821081489 43.813740760406574 58.12192015470907 68.64444433000277]\ngs[ps[2]] =>\t[5.721701371820064; 7.922604490508093]\nps[2] =>\t[-68.7910133401225; 46.9647268373293]\n---------------\nx =>\t[5.201049930563784, 5.879123339142632, 5.879212493497006, 8.078001904382251, 6.594085038051688]\npred =>\t[3.4788968073592628; 1846.8725408483065]\ntarget =>\t[-0.308038160544388, 1841.2060727855267]\ncurrent_loss =>\t46.44973675763503\ngs[ps[1]] =>\t[39.392075703729695 44.52771550723541 44.52839075071965 61.181735764994855 49.94274242385642; 58.94316664892569 66.62772927679028 66.62873965739371 91.54747960451307 74.7303445427482]\ngs[ps[2]] =>\t[7.573869935807301; 11.332936125559627]\nps[2] =>\t[-71.3053726699468; 43.09245267241971]\n---------------\nx =>\t[9.942897933129355, 6.519864023243275, 9.707348288113408, 9.971068130102418, 6.892915305429175]\npred =>\t[22.335712325607645; 3014.810505386612]\ntarget =>\t[26.902524621928332, 3021.278698682901]\ncurrent_loss =>\t62.693299067983446\ngs[ps[1]] =>\t[-90.81469708415338 -59.54999038337252 -88.66327505364778 -91.0719930880061 -62.95730074866205; -128.62517151350556 -84.34348153571561 -125.57801024383478 -128.98959207193818 -89.1694171409293]\ngs[ps[2]] =>\t[-9.133624592641375; -12.936386592577946]\nps[2] =>\t[-71.50395546884347; 42.7834425780336]\n---------------\nx =>\t[8.107277331071227, 9.462915797757965, 6.390597192104631, 6.32478809506127, 7.539976643075683]\npred =>\t[10.192611566695419; 2021.1965782219545]\ntarget =>\t[8.80129951383563, 2019.2156382711123]\ncurrent_loss =>\t5.859872317275557\ngs[ps[1]] =>\t[22.559505333192675 26.33173760923592 17.78262979669419 17.599507816885694 20.980920763584972; 32.12005911535239 37.49093591046879 25.318778575159904 25.058050836235815 29.87248192137113]\ngs[ps[2]] =>\t[2.7826241057195773; 3.9618799016843695]\nps[2] =>\t[-73.6610948231352; 39.46272063768593]\n---------------\nx =>\t[9.770189872539635, 8.941814727903868, 9.488389307408992, 8.943402024428142, 9.799053905492174]\npred =>\t[36.75015560684993; 2958.207671457844]\ntarget =>\t[41.247334275018815, 2964.31356171575]\ncurrent_loss =>\t57.50651181502637\ngs[ps[1]] =>\t[-87.87657895748985 -80.42587689809528 -85.34196397712293 -80.44015361023334 -88.13619238403282; -119.31141432126597 -109.19547887021973 -115.8701276706587 -109.21486258698768 -119.66389555648355]\ngs[ps[2]] =>\t[-8.994357336337771; -12.21178051581228]\nps[2] =>\t[-74.21558195821082; 38.6040652815749]\n---------------\nx =>\t[8.07667954611113, 7.021152483346666, 5.580177533263063, 6.150606465775391, 5.366222841989607]\npred =>\t[-6.1056169875356545; 1769.4504581614583]\ntarget =>\t[-9.78715823304588, 1763.1028940691106]\ncurrent_loss =>\t53.84531584885535\ngs[ps[1]] =>\t[59.469257751553855 51.69732491691458 41.08730749195494 45.28742277730795 39.51194145076767; 102.53448214458888 89.13443078037889 70.84106907813239 78.0827374966354 68.12488684669893]\ngs[ps[2]] =>\t[7.3630824910204495; 12.695128184695477]\nps[2] =>\t[-78.36459472528888; 32.211056543389205]\n---------------\nx =>\t[8.136792166458934, 8.146177756790511, 8.101230058270698, 5.660649201764269, 7.350719438883338]\npred =>\t[8.322644738914931; 2525.8140958952467]\ntarget =>\t[8.300881163930084, 2525.238613983031]\ncurrent_loss =>\t0.33165308448363356\ngs[ps[1]] =>\t[0.3541713729016937 0.3545799008996104 0.35262345568534587 0.24639192673102497 0.3199558674014239; 9.365153430512075 9.375955905454655 9.324222730466895 6.515202454027881 8.460412157700345]\ngs[ps[2]] =>\t[0.043527149969694534; 1.1509638244315283]\nps[2] =>\t[-79.24179628137244; 30.863577831249916]\n---------------\nx =>\t[8.132391790415454, 5.383832652302875, 8.143537790116412, 6.350657058765372, 5.597714892775953]\npred =>\t[-1.1778630878008869; 2530.2469836995365]\ntarget =>\t[-3.462211549008061, 2527.072711516078]\ncurrent_loss =>\t15.294251786897787\ngs[ps[1]] =>\t[37.1544333447388 24.597099669370024 37.205356039269795 29.014227359690313 25.57426280317846; 51.6288500906036 34.1795004572009 51.69961096421877 40.3174280966462 35.53734135013983]\ngs[ps[2]] =>\t[4.5686969224143485; 6.34854436691694]\nps[2] =>\t[-81.6129494381351; 27.206924603661232]\n---------------\nx =>\t[7.063537815191207, 6.248436155696099, 9.620026699616378, 9.491664638755989, 6.954066473752799]\npred =>\t[20.097978002803558; 2976.7093353244522]\ntarget =>\t[21.427326982167923, 2978.3467480563363]\ncurrent_loss =>\t4.44828916347313\ngs[ps[1]] =>\t[-18.779813570652056 -16.612704452396013 -25.57674534918595 -25.23546939999822 -18.488762338630465; -23.131853501477327 -20.46253783140308 -31.50390839803308 -31.08354505254572 -22.773353964981972]\ngs[ps[2]] =>\t[-2.6586979587287303; -3.2748254637681384]\nps[2] =>\t[-82.35769348554672; 26.060974008698864]\n---------------\nx =>\t[9.80627757692316, 6.521133710660103, 6.216187064928497, 6.175196972506677, 7.073714788845585]\npred =>\t[2.898672652112353; 1964.7049754630411]\ntarget =>\t[1.2626134698182747, 1963.1160590409074]\ncurrent_loss =>\t5.201345044494948\ngs[ps[1]] =>\t[32.08730094769932 21.337921372585832 20.340099852867887 20.205975418688283 23.146032066440473; 31.162710963949486 20.72307288759511 19.754003421040032 19.623743759052413 22.479083186973632]\ngs[ps[2]] =>\t[3.2721183645881564; 3.1778328442674137]\nps[2] =>\t[-82.55914441200129; 25.752166287651313]\n---------------\nx =>\t[7.45869893961911, 9.103239556791012, 5.6800176965957805, 8.411872179071423, 7.559582399177387]\npred =>\t[14.499244053424533; 1808.6188117033882]\ntarget =>\t[14.263352773692556, 1807.4494577690166]\ncurrent_loss =>\t1.423033319684062\ngs[ps[1]] =>\t[3.51888407600458 4.29474965751637 2.679733286700507 3.96857458652594 3.566479132762562; 17.443717900674617 21.28981798252253 13.28390208162982 19.6729116560573 17.679654841369608]\ngs[ps[2]] =>\t[0.47178255946395353; 2.338707868743313]\nps[2] =>\t[-89.4026336656995; 15.207885277038]\n---------------\nx =>\t[5.655402223251164, 6.83668082665157, 5.940260360136811, 8.594210659399256, 7.290828306284258]\npred =>\t[9.867187486796198; 1871.082198930316]\ntarget =>\t[8.081444620695557, 1867.7353782754183]\ncurrent_loss =>\t14.390086079879758\ngs[ps[1]] =>\t[20.19818835020094 24.417108028000147 21.21555512178947 30.694100749576613 26.039089271823464; 37.85523394506368 45.76228920316225 39.76197213755285 57.526563494840254 48.80218953357115]\ngs[ps[2]] =>\t[3.571485732201282; 6.6936413097955665]\nps[2] =>\t[-91.14563798080482; 12.519431513108765]\n---------------\nx =>\t[5.198783834523098, 6.496326924071557, 8.2926328763796, 6.0049991480570135, 6.558376007711266]\npred =>\t[1.6921246164799015; 2564.1429591384826]\ntarget =>\t[-0.11114771114579197, 2561.646265772856]\ncurrent_loss =>\t9.485268849543816\ngs[ps[1]] =>\t[18.74964605220659 23.429293146775954 29.907750778268777 21.657297582214152 23.653075937739995; 25.95953821795992 32.438672664540135 41.4083229720658 29.9852830670931 32.74850773547307]\ngs[ps[2]] =>\t[3.606544655251387; 4.99338673125294]\nps[2] =>\t[-92.46305632533752; 10.488590041390175]\n---------------\nx =>\t[5.635568953845485, 6.865266879284139, 6.662201393357896, 9.24418683527761, 7.240782194560622]\npred =>\t[12.14707983380211; 2085.776404583582]\ntarget =>\t[12.399712764581135, 2086.1883456126466]\ncurrent_loss =>\t0.23351880914077244\ngs[ps[1]] =>\t[-2.8474606028345444 -3.468784984587454 -3.3661829268882264 -4.670772025730137 -3.6585200538888696; -4.643044148422843 -5.656170206110361 -5.488868195630456 -7.6161196755787195 -5.965550536919359]\ngs[ps[2]] =>\t[-0.5052658615580512; -0.8238820581291293]\nps[2] =>\t[-95.2061336188353; 6.264384565818323]\n---------------\nx =>\t[5.672489502180572, 7.137538125150752, 6.935684562216434, 8.784215244369795, 6.230858087675193]\npred =>\t[7.561234739783629; 2167.865680760087]\ntarget =>\t[7.009523862194727, 2167.0349845260234]\ncurrent_loss =>\t0.994441125737119\ngs[ps[1]] =>\t[6.259148322723754 7.875714845702334 7.6529852330004555 9.69269420280214 6.875264367366376; 9.424231334451742 11.858252082094094 11.522894092970436 14.594029045401522 10.351900696831178]\ngs[ps[2]] =>\t[1.1034217551778038; 1.6613924681269054]\nps[2] =>\t[-95.3128722726062; 6.099751559836653]\n---------------\nx =>\t[6.347503217357707, 5.654960144930728, 7.050410826369625, 9.965139415589395, 6.11296602421222]\npred =>\t[9.0599399779273; 2202.201997211129]\ntarget =>\t[9.363964481319211, 2202.1136274697155]\ncurrent_loss =>\t0.10024010986015476\ngs[ps[1]] =>\t[-3.8595930268714724 -3.438492899527231 -4.28699530039196 -6.059293124111455 -3.7169829195254938; 1.1218544358761922 0.9994547314202803 1.2460859631678638 1.7612335866065687 1.0804024536560486]\ngs[ps[2]] =>\t[-0.6080490067838227; 0.17673948282663332]\nps[2] =>\t[-96.12058588104517; 4.857463911068353]\n---------------\nx =>\t[9.777351884559106, 9.073579506315435, 5.305247273917343, 9.797673867105852, 8.597419986732175]\npred =>\t[24.995395486617994; 1710.5245594789826]\ntarget =>\t[26.175752339486234, 1711.4031199233164]\ncurrent_loss =>\t2.16511075446092\ngs[ps[1]] =>\t[-23.08152859968708 -21.420123500648486 -12.524169951857766 -23.12950298241292 -20.29604719665139; -17.179989232211224 -15.943376085532071 -9.321960804546402 -17.215697412243244 -15.106706247334452]\ngs[ps[2]] =>\t[-2.3607137057364795; -1.7571208886674867]\nps[2] =>\t[-96.1996183396579; 4.731817060521341]\n---------------\nx =>\t[8.42072836367306, 9.3647694010882, 9.056452360882627, 7.070909529088602, 5.10805767797557]\npred =>\t[8.872050009185457; 2820.0739164231486]\ntarget =>\t[8.228341134298768, 2819.997365346627]\ncurrent_loss =>\t0.4202211829245356\ngs[ps[1]] =>\t[10.840995161412838 12.056370349495564 11.659437519377317 9.10321443479039 6.57620412149194; 1.2892316426738177 1.4337663580636075 1.3865623553880981 1.0825714728801084 0.7820546283690498]\ngs[ps[2]] =>\t[1.287417749773379; 0.15310215304361918]\nps[2] =>\t[-96.30601598590196; 4.563419597349832]\n---------------\nx =>\t[8.198395896123102, 7.6617586537426465, 7.674924747478488, 8.761466236547234, 7.11284783949618]\npred =>\t[17.051911377317182; 2404.009347739471]\ntarget =>\t[17.503578582974917, 2404.149604236478]\ncurrent_loss =>\t0.22367514961925794\ngs[ps[1]] =>\t[-7.405893130555526 -6.92113024311982 -6.93302362865401 -7.91453394505176 -6.425280215867792; -2.299756578928717 -2.149222859369477 -2.152916119742779 -2.457705125961238 -1.9952462434188636]\ngs[ps[2]] =>\t[-0.9033344113154698; -0.28051299401340657]\nps[2] =>\t[-98.55471918239859; 1.1029164940471525]\n---------------\nx =>\t[8.230861939702576, 9.74546753527152, 8.47309801046038, 7.936561351394312, 8.350143260516882]\npred =>\t[26.28860592163025; 2650.7336174552042]\ntarget =>\t[26.63895660260686, 2651.1074067697837]\ncurrent_loss =>\t0.262464051354532\ngs[ps[1]] =>\t[-5.7673761711985305 -6.82866237483566 -5.937111315892721 -5.561159348147296 -5.850956755148694; -6.153216485678621 -7.285503260530378 -6.334306995388567 -5.933203655310486 -6.242388651977238]\ngs[ps[2]] =>\t[-0.7007013619532216; -0.747578629158852]\nps[2] =>\t[-98.81046563001061; 0.7130485210397078]\n---------------\nx =>\t[5.421239780260826, 8.150093089994947, 9.1101057209511, 9.727875792137121, 7.5981067869973415]\npred =>\t[26.19284877750644; 2826.0797768500565]\ntarget =>\t[26.27162948310371, 2826.5048854436805]\ncurrent_loss =>\t0.1869237159473087\ngs[ps[1]] =>\t[-0.8541781902018497 -1.2841401686264369 -1.4354011135244675 -1.5327378377342857 -1.19716842776608; -4.609231237369434 -6.929349222783525 -7.745568461597461 -8.270807193887135 -6.46004098084957]\ngs[ps[2]] =>\t[-0.1575614111945356; -0.8502171872478357]\nps[2] =>\t[-99.17811478936568; 0.13975183684583337]\n---------------\nx =>\t[8.403214542851863, 5.4637730272593, 9.464059637811491, 6.126108473550499, 5.407092310295194]\npred =>\t[-0.14329376630925594; 2924.3891542677743]\ntarget =>\t[-0.6818618703441419, 2924.026673619358]\ncurrent_loss =>\t0.42144782316002916\ngs[ps[1]] =>\t[9.051406648284217 5.885227760335981 10.194081311218449 6.598653251424283 5.824174907794588; 6.092005312548359 3.961023979440824 6.861076948328782 4.441191543522283 3.919932653365125]\ngs[ps[2]] =>\t[1.077136208069772; 0.7249612968325891]\nps[2] =>\t[-99.79450445103765; -0.8077620029139135]\n---------------\nx =>\t[6.471913704985612, 7.705444392672555, 8.178922503664019, 5.911026114540293, 9.944276461952983]\npred =>\t[19.813280977510445; 2541.668151941998]\ntarget =>\t[19.684002471287062, 2541.4838274851063]\ncurrent_loss =>\t0.05068843757979609\ngs[ps[1]] =>\t[1.6733586723743545 1.9922966817440941 2.1147177675809847 1.5283372526703483 2.571162412947251; 2.385863957443785 2.840603705578246 3.015150896895534 2.1790933564714483 3.6659467160622423]\ngs[ps[2]] =>\t[0.2585570124467651; 0.36864891378354514]\nps[2] =>\t[-99.91763907223711; -0.9944910196665342]\n---------------\nx =>\t[8.982544537444614, 7.898214971330536, 8.679172719712724, 6.454547055484834, 7.037261642773518]\npred =>\t[12.01945759114166; 2703.704905395801]\ntarget =>\t[11.72489433031473, 2703.6882975767726]\ncurrent_loss =>\t0.08704333428186725\ngs[ps[1]] =>\t[5.291855218945625 4.6530479133344 5.1131308351974285 3.802544855648944 4.145837473575291; 0.2983609481811649 0.2623442497792771 0.28828425968687327 0.21439189881292312 0.23374713563448282]\ngs[ps[2]] =>\t[0.5891265216538599; 0.03321563805639016]\nps[2] =>\t[-100.08541260976502; -1.2531691550687722]\n---------------\nx =>\t[9.62192957185627, 6.795427168025086, 5.535096872847279, 5.652413184753744, 8.09077580140869]\npred =>\t[2.836471574461953; 1758.059190352223]\ntarget =>\t[2.463298895407459, 1758.3788398127879]\ncurrent_loss =>\t0.24143362603217877\ngs[ps[1]] =>\t[7.181282472006535 5.071735523223233 4.131093857733145 4.218652342555001 6.0385129628819065; -6.151289194475796 -4.344309257135392 -3.5385814591608646 -3.613581650793609 -5.172424240944647]\ngs[ps[2]] =>\t[0.7463453581089885; -0.6392989211299209]\nps[2] =>\t[-100.16194692257643; -1.3720610680984633]\n---------------\nx =>\t[7.543307299653746, 5.5183314269251245, 5.22812758569566, 5.694926870940346, 8.056046224747252]\npred =>\t[-2.874177599184037; 1650.5646596861911]\ntarget =>\t[-2.738913133178481, 1650.5286359135782]\ncurrent_loss =>\t0.019594187957034704\ngs[ps[1]] =>\t[-2.040682867606956 -1.4928683074094118 -1.4143597721760823 -1.540642484276878 -2.179393581413028; 0.543476773824018 0.39758223305241996 0.3766737586767351 0.4103055012917794 0.5804183547187278]\ngs[ps[2]] =>\t[-0.2705289320111124; 0.07204754522581425]\nps[2] =>\t[-100.16647844556252; -1.377799000976817]\n---------------\nx =>\t[6.3590988150611985, 8.130220736669003, 9.052446654141534, 5.859871712468653, 7.289372329248824]\npred =>\t[9.649101526285534; 2801.942283658593]\ntarget =>\t[10.091998531634031, 2801.912337720273]\ncurrent_loss =>\t0.19705451656853173\ngs[ps[1]] =>\t[-5.632851643811562 -7.201700834185906 -8.018603028392615 -5.190639266357471 -6.456882350989006; 0.380858361773182 0.486934177416507 0.5421680182999778 0.35095871372936727 0.43657418832636163]\ngs[ps[2]] =>\t[-0.8857940106969941; 0.059891876639994734]\nps[2] =>\t[-100.32858735270564; -1.6278600889354387]\n---------------\nx =>\t[9.395982160473306, 9.170646509830085, 8.330450988994329, 6.598354009530433, 6.42025396213381]\npred =>\t[11.183056201914184; 2606.0939161139045]\ntarget =>\t[11.676625600255612, 2606.1110710677417]\ncurrent_loss =>\t0.24390504342027708\ngs[ps[1]] =>\t[-9.275138523543205 -9.052700960517507 -8.223311365101374 -6.513491237055373 -6.33768177057911; -0.3223752804367996 -0.31464403506746424 -0.2858170043190868 -0.2263889168704534 -0.22027832068745665]\ngs[ps[2]] =>\t[-0.9871387966828564; -0.03430990767446929]\nps[2] =>\t[-100.36677151184932; -1.6869893447500204]\n---------------\nx =>\t[7.8143192892247235, 9.699765853357817, 8.712952444014755, 8.749681553134003, 5.743756934009722]\npred =>\t[17.20477631443562; 2720.2568796872197]\ntarget =>\t[17.28821778751129, 2720.6319515890254]\ncurrent_loss =>\t0.1476414109532334\ngs[ps[1]] =>\t[-1.3040766251530647 -1.6187255025865162 -1.454043173533698 -1.4601726354730322 -0.9585350791247285; -5.8618631942540285 -7.276219251379129 -6.535967287039657 -6.563519400657633 -4.308643673498187]\ngs[ps[2]] =>\t[-0.1668829461513397; -0.750143803611536]\nps[2] =>\t[-100.45063374673684; -1.823121277927638]\n---------------\nx =>\t[6.499635068282499, 5.863772932337639, 5.2887956176081, 8.466573530561128, 8.286587426936345]\npred =>\t[9.186250344373548; 1673.1612766753735]\ntarget =>\t[9.163313904542052, 1673.0648465927702]\ncurrent_loss =>\t0.009824841103026833\ngs[ps[1]] =>\t[0.2981569773406767 0.26898815009622595 0.24261228492868833 0.38838610872529195 0.3801296278527017; 1.2535206930518277 1.1308882164648555 1.0199979965560468 1.6328647698381764 1.5981526201582017]\ngs[ps[2]] =>\t[0.045872879662990584; 0.19286016520663907]\nps[2] =>\t[-100.47581014655853; -1.8548122777316274]\n---------------\nx =>\t[5.804718584794035, 8.639169240343685, 8.842222548367678, 8.27331998891977, 6.405703743564591]\npred =>\t[14.90090155350056; 2744.6001930777165]\ntarget =>\t[14.861448260060026, 2744.302813225994]\ncurrent_loss =>\t0.08999133857369739\ngs[ps[1]] =>\t[0.4580305313312012 0.6816873582434302 0.6977096017345137 0.6528194425005752 0.5054522189759626; 3.4524127040717585 5.138229735394967 5.258997660658772 4.920637343112631 3.8098544588767713]\ngs[ps[2]] =>\t[0.07890658688106811; 0.5947597034446517]\nps[2] =>\t[-100.47955551759053; -1.8585956651272353]\n---------------\nx =>\t[5.313006670707398, 5.247913972040842, 8.298549744225653, 8.029192055983291, 9.618171187501382]\npred =>\t[21.065758660540325; 2567.9746089219157]\ntarget =>\t[21.00949074262798, 2567.587004121633]\ncurrent_loss =>\t0.15340355978829534\ngs[ps[1]] =>\t[0.5979036464301949 0.5905783851796697 0.933884231599177 0.9035718390170173 1.082388933690391; 4.1186937789992 4.06823329406619 6.433115432491416 6.224306766579895 7.456098644430436]\ngs[ps[2]] =>\t[0.11253583582468707; 0.7752096005651765]\nps[2] =>\t[-100.58508042641984; -2.0210692128264585]\n---------------\nx =>\t[6.96601544544508, 5.310725844282581, 9.451107815687687, 5.034701243274945, 6.844130094837791]\npred =>\t[0.5939202131917654; 2910.493330967293]\ntarget =>\t[0.46989408186335274, 2910.353351957762]\ncurrent_loss =>\t0.034976604361597385\ngs[ps[1]] =>\t[1.7279358929450443 1.3173375620243728 2.344368678294936 1.2488690351954812 1.6977019559421858; 1.9501918848633415 1.4867802871476654 2.645913422022995 1.4095049866371394 1.9160691035546258]\ngs[ps[2]] =>\t[0.24805226265682523; 0.2799580190621782]\nps[2] =>\t[-100.66222511768291; -2.146486661104506]\n---------------\nx =>\t[6.562446417120794, 6.0453200159748555, 7.395388433397859, 6.792970917412018, 5.976875645133751]\npred =>\t[-2.096214983851766; 2298.897696541392]\ntarget =>\t[-1.9307823568936415, 2298.906089393899]\ncurrent_loss =>\t0.02743839403546788\ngs[ps[1]] =>\t[-2.1712855001124507 -2.0001863420905037 -2.446877071825474 -2.247558047435223 -1.9775404779530235; -0.11015528972611521 -0.10147495850167428 -0.12413680870487287 -0.11402480598643827 -0.10032607148288603]\ngs[ps[2]] =>\t[-0.3308652539162491; -0.016785705013717234]\nps[2] =>\t[-100.6811195999645; -2.172353972508324]\n---------------\nx =>\t[7.874275154308644, 6.683472074434978, 6.851042532548933, 7.659376266944267, 9.805294264589367]\npred =>\t[21.18904053611243; 2151.1971539169717]\ntarget =>\t[21.548044567043128, 2150.941100494756]\ncurrent_loss =>\t0.1944472492528616\ngs[ps[1]] =>\t[-5.653793042108503 -4.79878683066983 -4.9191037705254566 -5.499493908495836 -7.040280330898485; 4.0324702014575795 3.4226517938842833 3.5084657724089445 3.922419010377589 5.021358304560171]\ngs[ps[2]] =>\t[-0.7180080618613971; 0.5121068444314005]\nps[2] =>\t[-100.6830257672136; -2.1736162612243386]\n---------------\nx =>\t[7.742415649380012, 5.747407829497573, 8.90776997733522, 9.088094349939304, 5.324337702186051]\npred =>\t[9.166965250764562; 2763.426188920554]\ntarget =>\t[9.338329522509808, 2763.209476943293]\ncurrent_loss =>\t0.0763297947192303\ngs[ps[1]] =>\t[-2.6535468386099956 -1.9698007142495473 -3.052947030080424 -3.114749339658858 -1.824802505721733; 3.355748408310154 2.4910642297136585 3.8608408895522572 3.9389977922230837 2.3076955020940173]\ngs[ps[2]] =>\t[-0.342728543490491; 0.43342395452236815]\nps[2] =>\t[-100.694224341659; -2.190896264442863]"}],"source":["# opt = Descent(0.0001)\ndecay = 0.99999999999999\ndecay = 0.1\nfor _ in 1:50\n    for (x, target) in train_data\n        current_loss = nothing\n        pred = nothing\n        gs = Flux.gradient(ps) do\n            pred = model(x)\n            current_loss = loss(x, target, pred)\n            # for p in ps\n            #     current_loss += 0.001*sum(abs2,p)\n            # end\n            current_loss\n        end\n        push!(losses, current_loss)\n        if current_loss < min_loss\n            min_loss = current_loss\n            best_W = W\n            best_b = b\n        end\n\n        if rand() <= 0.0001\n            println(\"---------------\")\n            @labeled x\n            @labeled pred\n            @labeled target\n            @labeled current_loss\n            @labeled gs[ps[1]]\n            @labeled gs[ps[2]]\n            @labeled ps[2]\n            # @labeled gs[b]\n            # @labeled b\n        end\n\n        #### Optimization\n        # Flux.Optimise.update!(opt, ps, gs)\n        ###\n        W_step = decay*0.01*normalize(gs[W])*min(1000,norm(gs[W]))\n        b_step = decay*0.01*normalize(gs[b])*min(1000,norm(gs[b]))\n        ##\n        W .-= W_step\n        b .-= b_step\n        ##\n        # Flux.update!(W, W_step)\n        # Flux.update!(b, b_step)\n        ##\n        # decay *= decay\n        ####\n    end\nend\n\nnothing"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["println(lineplot(losses))\n@labeled minimum(losses)\n@labeled length(losses)\n\n# we need to use the loss of a batch for this to work\n# W = best_W\n# b = best_b\n\nbella()"]},{"cell_type":"markdown","metadata":{},"source":["## Hello Flux test\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[NaN NaN NaN NaN NaN; NaN NaN NaN NaN NaN]\n[NaN, NaN]"}],"source":["using Flux\n\nW_truth = [1 2 3.1 4 5;\n            5 4 300 2.9 1]\nb_truth = [-100.78; -2.3]\nground_truth(x) = W_truth*x .+ b_truth\n\nx_train = [((rand(5).*5) .+ 5) for _ in 1:10_000]\ny_train = [ ground_truth(x) + 0.2 .* randn(2) for x in x_train ]\n\nmodel(x) = W*x .+ b\n\nW = rand(2, 5)\nb = rand(2)\n\nfunction loss(x, y)\n  pred = model(x)\n  # sum(sqrt.((y .- pred).^2))\n  sum(((y .- pred).^2))\nend\n\nopt = Descent(0.01)\n\ntrain_data = zip(x_train, y_train)\nps = Flux.params(W, b)\n\nfor (x,y) in train_data\n  gs = Flux.gradient(ps) do\n    loss(x,y)\n  end\n  Flux.Optimise.update!(opt, ps, gs)\nend\n\nprintln(ps[1] - W_truth)\nprintln(ps[2] - b_truth)\nnothing"]},{"cell_type":"markdown","metadata":{},"source":["## Classifying books\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Data preprocessing\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"book_get (generic function with 1 method)"}],"source":["PART_ONE_SIZE = 500\nPART_BIG_SIZE = PART_ONE_SIZE * 4\nSAMPLE_SIZE = 650 # Can cause GPU-OOM (550 is around 7GB)\nrng = MersenneTwister(1234);\n\nBook = Dict{Symbol, Any}\n\nfunction bigPartSplit(parts)\n    return vcat((map(parts) do s\n                     collect(Iterators.partition(s, PART_ONE_SIZE))\n                 end)...)\nend\n\nfunction text_to_bytes(text)\n    convert(Vector{Float32}, codeunits(text))\nend\n\nfunction book_get(path; part_size=PART_BIG_SIZE, sample_size=SAMPLE_SIZE)\n    book = Book()\n    book[:path] = path\n    book[:text] = open(f->read(f,String), book[:path])\n    book[:bytes] = text_to_bytes(book[:text])\n    book[:parts] = (collect(Iterators.partition(book[:bytes], part_size)))\n    pop!(book[:parts]) # the last entry might not be complete, so we just skip it instead of padding etc\n\n    sample_size = min(sample_size, length(book[:parts]))\n    train_size = floor(Int, sample_size*0.8)\n    # valid_size = floor(Int, sample_size*0.2)\n\n    # @todo I think only :train_samples need to be moved to the gpu\n    book[:part_samples] = map(gpu, sample(rng, book[:parts], sample_size; replace=false))\n    book[:train_samples] = book[:part_samples][1:train_size]\n    book[:train_samples_split] = bigPartSplit(book[:train_samples])\n    book[:valid_samples] = book[:part_samples][(train_size+1):end]\n    book[:valid_samples_split] = bigPartSplit(book[:valid_samples])\n\n        #: You can use =String(book[:parts][1])= to get the string back\n\n        return book\nend"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["dir_base = \"$(homedir())/base/archives/nlp_data\"\nBooks = Dict{Symbol, Book}\nbooks = Books()\n\nfunction books_load(path::AbstractString\n                    ; name::Union{Symbol,Nothing}=nothing\n                    , verbosity::UInt8=0x01)\n    if name === nothing\n        name = Symbol(replace(fileNameNoExt(path), r\"\\s+\" => \"_\"))\n    end\n\n    book = book_get(path)\n    book[:name] = name\n    books[name] = book\n\n    if verbosity >= 1\n        println(\"Loaded book $(name)\")\n        @labeled length(book[:part_samples])\n        display(book)\n    end\n\n    return book\nend\n\nelizium = nothing # for GC\nluminary = nothing\n\nnothing"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Dict{Symbol, Any} with 10 entries:\n  :part_samples        => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…\n  :valid_samples       => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…\n  :path                => \"/Users/evar/base/archives/nlp_data/Voice of the Neph…\n  :name                => :elizium\n  :text                => \"Elizium for the Sleepless Souls\\n\\nBy: Voice of the …\n  :valid_samples_split => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…\n  :bytes               => Float32[69.0, 108.0, 105.0, 122.0, 105.0, 117.0, 109.…\n  :train_samples       => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…\n  :train_samples_split => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…\n  :parts               => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…Loaded book elizium\nlength(book[:part_samples]) =>\t150\nDict{Symbol, Any} with 10 entries:\n  :part_samples        => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…\n  :valid_samples       => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…\n  :path                => \"/Users/evar/base/archives/nlp_data/Voice of the Neph…\n  :name                => :elizium\n  :text                => \"Elizium for the Sleepless Souls\\n\\nBy: Voice of the …\n  :valid_samples_split => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…\n  :bytes               => Float32[69.0, 108.0, 105.0, 122.0, 105.0, 117.0, 109.…\n  :train_samples       => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…\n  :train_samples_split => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…\n  :parts               => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…"}],"source":["elizium = books_load(\"$(dir_base)/Voice of the Nephilim/Elizium for the Sleepless Souls.txt\"; name=:elizium)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"----------------------------------------\nDict{Symbol, Any} with 10 entries:\n  :part_samples        => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…\n  :valid_samples       => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…\n  :path                => \"/Users/evar/base/archives/nlp_data/YakAge/Black Lumi…\n  :name                => :luminary\n  :text                => \"Black Luminary\\n\\nBy: YakAge\\n\\nThe war against the …\n  :valid_samples_split => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…\n  :bytes               => Float32[66.0, 108.0, 97.0, 99.0, 107.0, 32.0, 76.0, 1…\n  :train_samples       => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…\n  :train_samples_split => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…\n  :parts               => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…Loaded book luminary\nlength(book[:part_samples]) =>\t650\nDict{Symbol, Any} with 10 entries:\n  :part_samples        => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…\n  :valid_samples       => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…\n  :path                => \"/Users/evar/base/archives/nlp_data/YakAge/Black Lumi…\n  :name                => :luminary\n  :text                => \"Black Luminary\\n\\nBy: YakAge\\n\\nThe war against the …\n  :valid_samples_split => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…\n  :bytes               => Float32[66.0, 108.0, 97.0, 99.0, 107.0, 32.0, 76.0, 1…\n  :train_samples       => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…\n  :train_samples_split => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…\n  :parts               => SubArray{Float32, 1, Vector{Float32}, Tuple{UnitRange…"}],"source":["hsep()\nluminary = books_load(\"$(dir_base)/YakAge/Black Luminary.txt\"; name=:luminary)"]},{"cell_type":"markdown","metadata":{},"source":["#### Assertions\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["for book in values(books)\n    for ds in [:valid_samples, :train_samples]\n        for (i, part) in enumerate(book[ds])\n            @assert length(part) == PART_BIG_SIZE \"$(ds): i=$i, length(part)=$(length(part))\"\n        end\n    end\n\n    for ds in [:valid_samples_split, :train_samples_split]\n        for (i, part) in enumerate(book[ds])\n            @assert length(part) == PART_ONE_SIZE \"$(ds): i=$i, length(part)=$(length(part))\"\n        end\n    end\nend"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"500"}],"source":["length(elizium[:train_samples_split][end])"]},{"cell_type":"markdown","metadata":{},"source":["### Model\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"validate (generic function with 1 method)"}],"source":["model_selected = :m1\n\nfunction ps_init()\n    eclog(\"\\n---------------------------\\nps_init()\")\n    ##\n    global i_last = 0\n    global losses = Float64[]\n    global accu_v = Bool[]\n\n    global book_names = collect(keys(books))\n    global books_v = collect(values(books))\n\n    global is = IdDict{Book, Int}()\n    ##\n    out_len = length(books_v)\n    if out_len == 2\n        out_len -= 1\n        # @todo Can't we always decrease this even for multiple classes?\n    end\n\n    if model_selected == :m1\n        lc1_s = 4\n        lc1_c = 32\n        global model1 = Chain(\n            # x -> reshape(x, :, 1), # Fake batching\n            x -> reshape(x, :, 1, size(x, 2)),\n            Conv((lc1_s,), 1=>lc1_c, relu),\n            x -> reshape(x, :, size(x, 3)),\n            Dense((PART_ONE_SIZE - (lc1_s - 1))*lc1_c, 128, relu),\n            Dense(128, 64, relu),\n            Dense(64, 32, relu),\n            Dense(32, out_len),\n        ) |> gpu\n\n        global ps = Flux.params(model1)\n    elseif model_selected == :m0\n        rnd = Flux.glorot_uniform\n        l1 = 128\n        global W1 = rnd(l1, PART_ONE_SIZE) |> gpu\n        global b1 = rnd(l1, 1) |> gpu\n\n        l2 = 64\n        global W2 = rnd(l2, l1) |> gpu\n        global b2 = rnd(l2, 1) |> gpu\n\n        l3 = 16\n        global W3 = rnd(l3, l2) |> gpu\n        global b3 = rnd(l3, 1) |> gpu\n\n        global W_last = rnd(out_len, l3) |> gpu\n        global b_last = rnd(out_len, 1) |> gpu\n\n        global ps = Flux.params(W1, b1, W2, b2, W3, b3, W_last, b_last)\n    end\n    ##\nend\n# ps_init()\n\nfunction predict_title_raw(text_part)\n    if model_selected == :m0\n        l1 = relu.(W1 * text_part .+ b1)\n        l2 = relu.(W2 * l1 .+ b2)\n        l3 = relu.(W3 * l2 .+ b3)\n        l_last = W_last * l3 .+ b_last\n    elseif model_selected == :m1\n        model1(text_part)\n    end\n    # using =logitcrossentropy= instead of =softmax=\nend\n\nfunction title_from_raw(raw)\n    raw = cpu(raw)\n\n    if length(books_v) == 2\n        raw = sigmoid.(raw)\n        res = map(raw) do x\n            if x >= 0.5f0\n                return book_names[1], x\n            else\n                return book_names[2], (1-x)\n            end\n        end\n\n        # These list-comprehensions are returning 1xn matrices instead of vectors. This is because =res= itself is a matrix.\n        return reshape([i[1] for i in res], :), reshape([i[2] for i in res], :)\n    else\n        # @todo/batch\n\n        raw = softmax(raw)\n        max_i = 0\n        max_p = -Inf\n        for (i, p) in enumerate(raw)\n            if p > max_p\n                max_p = p\n                max_i = i\n            end\n        end\n\n        return book_names[max_i], max_p\n    end\nend\n\nfunction pad_constant_to_length(arr, len; constant=0, kwargs...)\n    pad_n = len - length(arr)\n    if pad_n > 0\n        return Flux.pad_constant(arr, (0, pad_n), constant; kwargs...)\n    elseif pad_n < 0\n        return @view arr[1:len]\n    else\n        return arr\n    end\nend\n\nfunction predict_title(text::AbstractString)\n    text_bytes = text_to_bytes(text)\n    text_bytes = pad_constant_to_length(text_bytes, PART_ONE_SIZE)\n    predict_title(text_bytes)\nend\nfunction predict_title(text_bytes::Union{AbstractVector{UInt8}, AbstractVector{Float32}})\n    @assert length(text_bytes) == PART_ONE_SIZE \"predict_title: length(text_bytes)=$(length(text_bytes))\"\n    predict_title(reshape(text_bytes, :, 1))\nend\nfunction predict_title(batch::AbstractMatrix)\n    raw = predict_title_raw(batch)\n    title_from_raw(raw)\nend\n\nfunction loss_title(pred, target)\n    loss = 0\n    # loss = (10^-1)*norm(pred) # @todo decrease this further?\n\n    # if length(books_v) == 2\n        loss += Flux.Losses.logitbinarycrossentropy(pred, reshape(target[1, :], 1, :))\n    # else\n    #     loss += Flux.Losses.logitcrossentropy(pred, target)\n    # end\n\n    return loss\nend\n\nfunction validate()\n    hsep(log_file)\n\n    accu_mean = -Inf\n    for ds in (:train_samples_split, :valid_samples_split)\n        eclog(\"validate: $(ds)\")\n        accuracies = Float64[]\n\n        for book in values(books)\n            eclog(\"validate: $(book[:name])\")\n            samples = book[ds][1:end]\n            accu = sum(map(predict_title(hcat(samples...))[1]) do x\n                           x == book[:name]\n                       end) / length(samples)\n            push!(accuracies, accu)\n            eclog(accu)\n        end\n\n        accu_mean = mean(accuracies)\n        eclog(\"mean(accuracies)=$(accu_mean)\")\n    end\n\n    hsep(log_file)\n    flush(log_file)\n\n    return accu_mean\nend"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["if @isdefined books_v\n    # @labeled title_from_raw([0.2,0.8])\n    # @labeled title_from_raw([0.8,0.2])\n    # @labeled title_from_raw([10,9])\n\n    @labeled title_from_raw(Float32.([10 3 2]) |> gpu)\n    @labeled title_from_raw([-10 -4 1])\nend\n\nnothing"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"processBooks (generic function with 2 methods)"}],"source":["function processBooks(dataset::Symbol=:train_samples\n                      ; freeze=false\n                      , is = IdDict{Book, Int}()\n                      , valid_mode=false\n                      , losses=Float64[]\n                      , accu_v=Bool[]\n                      , batch_size = 64\n                      , i_t_start = 0\n                      , n=10^3\n                      , checkpoint=10^4\n                      , model_dir=\n                          \"$(dir_base)/processBooks/models/$(Dates.format(Dates.now(), \"yy-mm-dd HH:MM\")\n)\")\n    interrupted = false\n    i_t = i_t_start\n\n    # n = ceil(n / batch_size)\n    # checkpoint_n_batches = ceil(checkpoint / batch_size)\n    checkpoint_n_batches = checkpoint\n    # val_n_batches = ceil(10^5 / batch_size)\n    val_n_batches = 10^4\n    diag_n_batches = 10^4\n\n    function model_save()\n        accu = validate()\n\n        if valid_mode\n            return\n        end\n\n        dest = \"$(model_dir)/$(i_t)_accu=$(round(accu, digits=3))\"\n        ensureDir(\"$(model_dir)/\")\n        BSON.@save dest ps=Flux.params(cpu(model1)) i_last=i_t\n        # =opt= not saved\n        # cpu(ps) errors\n\n        eclog(\"Saved the model to: $(dest)\")\n        hsep(log_file)\n    end\n\n    try\n        i_books = 1\n        while i_t <= (i_t_start + n)\n            i_t += 1\n\n            input_batch = Matrix{Float32}(undef, PART_ONE_SIZE, batch_size) |> gpu\n            targets = Vector{Symbol}(undef, batch_size)\n            for i_batch in 1:batch_size\n                book = books_v[i_books]\n                i_books = (i_books % length(books_v)) + 1\n\n                data = book[dataset]\n\n                i = get!(is, book, 1)\n\n                is[book] = (i % length(data)) + 1\n\n                d = data[i]\n                d_size = rand(100:(PART_ONE_SIZE - 1)) # @hyperParam\n                i_d_start = rand(1:(PART_BIG_SIZE - (d_size)))\n                d = @view d[i_d_start:(i_d_start + d_size)]\n                d = pad_constant_to_length(d, PART_ONE_SIZE)\n                input_batch[:, i_batch] .= d\n\n                targets[i_batch] = book[:name]\n            end\n            target_onehot = Flux.onehotbatch(targets, book_names) |> gpu\n\n            loss_c = nothing\n            pred_raw = nothing\n            loss_calculate() = begin\n                pred_raw = predict_title_raw(input_batch)\n                loss_c = loss_title(pred_raw, target_onehot)\n                return loss_c\n            end\n            if ! valid_mode\n                # target_onehot = Flux.label_smoothing(target_onehot, 0.2f0) # @?\n\n                gs = gradient(loss_calculate, ps)\n\n                if ! (freeze)\n                    Flux.Optimise.update!(opt, ps, gs)\n                end\n            else\n                loss_calculate()\n            end\n            push!(losses, loss_c)\n            pred, pred_p = title_from_raw(pred_raw)\n            success = (pred .== targets)\n            append!(accu_v, success)\n            if true # ! valid_mode\n                eclog(\"$(i_t):. accu=$(mean(success)); loss: $(loss_c), mean(p): $(mean(pred_p)), mean(pred_raw): $(mean(pred_raw))\")\n                if i_t == i_t_start + 1 || i_t % diag_n_batches == 0\n                    eclog(\"p:\\n$(pred_p)\\npred_raw:\\n$(pred_raw)\\npred:\\n$(pred)\\ntargets:\\n$(targets)\\nsuccess:\\n$(success)\")\n                    # size(success): $(size(success))\n                end\n\n                if i_t % checkpoint_n_batches == 0\n                    model_save()\n                elseif i_t % val_n_batches == 0\n                    validate()\n                end\n            end\n        end\n    catch ex\n        if ex isa InterruptException || ex isa Flux.Optimise.StopException\n            eclog(\"Interrupted\")\n            interrupted = true\n        else\n            rethrow(ex)\n        end\n    end\n\n    model_save()\n\n    return losses, accu_v, i_t, interrupted\nend"]},{"cell_type":"markdown","metadata":{},"source":["### Training\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Params([Float32[0.055319645; -0.085456744; 0.19957349; 0.08606427]\n:\nFloat32[0.10556889; -0.041268174; -0.14451694; -0.15412125]\n:\nFloat32[-0.16258563; 0.11842584; 0.20073889; 0.118710846]\n:\n...\n:\nFloat32[0.18832041; -0.10462217; -0.1294518; -0.0067606773]\n:\nFloat32[-0.18592195; 0.08853288; -0.21216692; 0.019245688]\n:\nFloat32[-0.13922325; -0.026169788; -0.024823325; -0.076162495], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[-0.007998933 0.008388935 … 0.002452117 -0.007796853; 0.010862431 0.015860489 … 0.017589653 -0.011679318; … ; -0.006528453 0.0041661477 … 5.0855728f-5 -0.005960212; -0.013393072 0.009681716 … 0.010192597 0.009112317], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.1741361 0.09063144 … 0.15173556 -0.14428733; -0.11622107 0.091664165 … -0.08898337 0.045376055; … ; -0.15532534 0.15237123 … 0.01752234 -0.056859806; -0.13324068 0.14229198 … -0.07071508 0.123857066], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[-0.0887956 0.17488807 … 0.05877477 0.011693835; -0.20825922 -0.13366467 … 0.009864926 0.038101554; … ; 0.16201395 0.1249339 … -0.0790984 -0.014540076; 0.15982467 -0.1264543 … -0.12867141 -0.1762023], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[-0.4137816 0.09582225 … -0.13326377 -0.108566195], Float32[0.0]])"}],"source":["ps_init()"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"ADAM(0.001, (0.9, 0.999), IdDict{Any, Any}())"}],"source":["# opt = Flux.Optimise.ADAM(10^-4)\nopt = Flux.Optimise.ADAM()"]},{"cell_type":"markdown","metadata":{},"source":["#### Load\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"0.9067307692307692"}],"source":["# BSON.@load \"$(dir_base)/processBooks/models/21-11-06 00:39/150000_accu=0.82\" ps i_last # opt\n\nBSON.@load \"$(dir_base)/processBooks/models/good/230000_accu=0.899\" ps i_last # opt\n\n# BSON.@load \"$(dir_base)/processBooks/models/21-11-10 18:58/120000_accu=0.819\" ps i_last # opt\n\nFlux.loadparams!(model1, ps)\nmodel1 |> gpu\nps = Flux.params(model1)\n\nvalidate()"]},{"cell_type":"markdown","metadata":{},"source":["#### Epoch\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"43cdf771-e9ed-4c08-9597-0637f7935829"}],"source":["for i in 1:1\n    _, _, i_last, interrupted = @time processBooks(; n=10^6, losses, accu_v, is, i_t_start=i_last)\n    if interrupted\n        break\n    end\nend\nnothing"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"minimum(losses) =>\t0.2101973593235016\nlength(accu_v) =>\t1011200\nmean(accu_v) =>\t0.7409533227848101\nmean(accu_v[end - 200:end]) =>\t0.7562189054726368\n      \u001b[90m┌────────────────────────────────────────┐\u001b[39m\n   \u001b[90m60\u001b[39m \u001b[90m│\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n      \u001b[90m│\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n      \u001b[90m│\u001b[39m\u001b[38;5;2m⡆\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n      \u001b[90m│\u001b[39m\u001b[38;5;2m⡇\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n      \u001b[90m│\u001b[39m\u001b[38;5;2m⡇\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n      \u001b[90m│\u001b[39m\u001b[38;5;2m⡇\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n      \u001b[90m│\u001b[39m\u001b[38;5;2m⡇\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n      \u001b[90m│\u001b[39m\u001b[38;5;2m⡇\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n      \u001b[90m│\u001b[39m\u001b[38;5;2m⡇\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n      \u001b[90m│\u001b[39m\u001b[38;5;2m⡇\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n      \u001b[90m│\u001b[39m\u001b[38;5;2m⡇\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n      \u001b[90m│\u001b[39m\u001b[38;5;2m⡇\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n      \u001b[90m│\u001b[39m\u001b[38;5;2m⡇\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n      \u001b[90m│\u001b[39m\u001b[38;5;2m⡇\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n    \u001b[90m0\u001b[39m \u001b[90m│\u001b[39m\u001b[38;5;2m⣧\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n      \u001b[90m└────────────────────────────────────────┘\u001b[39m\n      ⠀\u001b[90m0\u001b[39m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[90m20000\u001b[39m⠀"}],"source":["@labeled minimum(losses)\n@labeled length(accu_v)\n@labeled mean(accu_v)\n@labeled mean(accu_v[end-200:end])\nlineplot(losses)"]},{"cell_type":"markdown","metadata":{},"source":["### Validation\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"| (0.3621591031551361 0.5376628041267395 0.44329220056533813) | Bool | (0 1 1 1 1 0 1 1 1 1 … 1 1 1 1 1 1 0 1 1 1) | 3 |"}],"source":["valid_losses, valid_accu_v, _ = processBooks(:valid_samples; valid_mode=true, n=100)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"mean(valid_losses) =>\t0.4477047026157379\nminimum(valid_losses) =>\t0.3621591031551361\nmaximum(valid_losses) =>\t0.5376628041267395\nmean(valid_accu_v) =>\t0.8020833333333334\n       \u001b[90m┌────────────────────────────────────────┐\u001b[39m\n   \u001b[90m0.6\u001b[39m \u001b[90m│\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n       \u001b[90m│\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n       \u001b[90m│\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n       \u001b[90m│\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[38;5;2m⣀\u001b[39m\u001b[38;5;2m⠔\u001b[39m\u001b[38;5;2m⠉\u001b[39m\u001b[38;5;2m⠒\u001b[39m\u001b[38;5;2m⠤\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n       \u001b[90m│\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[38;5;2m⡠\u001b[39m\u001b[38;5;2m⠊\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[38;5;2m⠉\u001b[39m\u001b[38;5;2m⠒\u001b[39m\u001b[38;5;2m⠤\u001b[39m\u001b[38;5;2m⣀\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n       \u001b[90m│\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[38;5;2m⢀\u001b[39m\u001b[38;5;2m⠤\u001b[39m\u001b[38;5;2m⠊\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[38;5;2m⠉\u001b[39m\u001b[38;5;2m⠑\u001b[39m\u001b[38;5;2m⠢\u001b[39m\u001b[38;5;2m⢄\u001b[39m\u001b[38;5;2m⡀\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n       \u001b[90m│\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[38;5;2m⢀\u001b[39m\u001b[38;5;2m⠔\u001b[39m\u001b[38;5;2m⠁\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[38;5;2m⠈\u001b[39m\u001b[38;5;2m⠑\u001b[39m\u001b[38;5;2m⠢\u001b[39m\u001b[38;5;2m⢄\u001b[39m\u001b[38;5;2m⡀\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n       \u001b[90m│\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[38;5;2m⡠\u001b[39m\u001b[38;5;2m⠔\u001b[39m\u001b[38;5;2m⠁\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[38;5;2m⠈\u001b[39m\u001b[38;5;2m⠉\u001b[39m\u001b[38;5;2m⠒\u001b[39m\u001b[38;5;2m⢤\u001b[39m\u001b[90m│\u001b[39m\n       \u001b[90m│\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[38;5;2m⡠\u001b[39m\u001b[38;5;2m⠊\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n       \u001b[90m│\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[38;5;2m⢀\u001b[39m\u001b[38;5;2m⠔\u001b[39m\u001b[38;5;2m⠊\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n       \u001b[90m│\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[38;5;2m⢀\u001b[39m\u001b[38;5;2m⠔\u001b[39m\u001b[38;5;2m⠁\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n       \u001b[90m│\u001b[39m\u001b[38;5;2m⡠\u001b[39m\u001b[38;5;2m⠊\u001b[39m\u001b[38;5;2m⠁\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n       \u001b[90m│\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n       \u001b[90m│\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n   \u001b[90m0.3\u001b[39m \u001b[90m│\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m\n       \u001b[90m└────────────────────────────────────────┘\u001b[39m\n       ⠀\u001b[90m1\u001b[39m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[90m3\u001b[39m⠀"}],"source":["@labeled mean(valid_losses)\n@labeled minimum(valid_losses)\n@labeled maximum(valid_losses)\n@labeled mean(valid_accu_v)\nlineplot(valid_losses)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"0.4984848484848485"}],"source":["validate()"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"book_names =>\t[:elizium, :luminary]\n2-element Vector{Symbol}:\n :elizium\n :luminary"}],"source":["@labeled book_names\ngetindex.(books_v,:name)"]},{"cell_type":"markdown","metadata":{},"source":["#### Manual testing\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"predict_title(\"Daphne\") =>\t([:luminary], Float32[0.8800906])\npredict_title(\"Sturges\") =>\t([:luminary], Float32[0.91894454])\npredict_title(\"Former\") =>\t([:luminary], Float32[0.87178886])\npredict_title(\"hjsiunx\") =>\t([:luminary], Float32[0.91926265])\npredict_title(\"Sturges closed his eyes and let out a deep sigh before responding.\") =>\t([:luminary], Float32[0.6961006])\npredict_title(\"Sturges gave a curt nod, before pointing his wand at the stone. Under his command, it rose into the air, made a loop and fell back to the ground.\\n\\n\\\"It worked,\\\" the Auror said, as if he couldn't believe it.\\n\\nHarry snorted.\") =>\t([:elizium], Float32[0.9949986])\npredict_title(\"Death Eaters aren't worth the regard you'd show a cockroach. The things they've done… they're not even human anymore. They all deserve to suffer, to live every moment in fear, in agony.\") =>\t([:luminary], Float32[0.8097029])\npredict_title(\"\\\"Death Eaters aren't worth the regard you'd show a cockroach. The things they've done… they're not even human anymore. They all deserve to suffer, to live every moment in fear, in agony.\\\"\\n\\nThe Auror opened his eyes, keeping his gaze level as he continued.\\n\\n\\\"For most of them, the Dementors do the job. But day after day, when you see that Bolshevik piece of shit sitting in his cell, like he's on a fucking vacation… someone has to balance the scales, Potter.\\\"\\n\") =>\t([:elizium], Float32[0.7296372])\npredict_title(\"\\\"I'm not a Healer, I wouldn't know,\\\" the Auror evasively replied. \\\"Besides, what does it matter now? The boat's gone, Azkaban is sinking, and we're standing around talking.\\\"\\n\\n\\\"It's important because there might be someone else loose on this island! If they found Personal Effects, then they're armed too.\\\"\\n\\nSturges froze for a moment, becoming a statue, before shaking his head.\\n\\n\\\"Shite, you've got a point - I can't say you're wrong. Bollocks, it's possible. I did a sweep around the Abyss, looking for others, but that doesn't mean I found them all.\\\" \") =>\t([:elizium], Float32[0.9999281])\npredict_title(\"As a way to light one's path, there was no finer spell than the Thief's Guide. It was a conjured light invisible to others, but it came with a price. The spell took almost thirty seconds to form, and required the same amount of time to wind down, before any other magic would channel through the wand.\\n\\nHe moved to within a foot of the high cliff face. Dolohov had the high ground, providing an eagle eye view of the island and Harry hoped to hide by sticking close to the rocky terrain. He flew along the shore, traveling in a counter-clockwise trajectory around the island, towards the north side.\\n\\nFrom behind him a bright light flashed, bathing everything in harsh white light. Harry started to bring his wand up, before the jagged roar of a thunderclap echoed through the air, so close it rattled his teeth within their sockets, filling his skull with ringing pain. Agony ripped through his head as he rose upward, until the overhang atop the walls of the Abyss stretched overhead, providing temporary reprieve from the storm.\\n\") =>\t([:elizium], Float32[0.5888242])"}],"source":["@labeled predict_title(\"Daphne\")\n\n@labeled predict_title(\"Sturges\")\n\n@labeled predict_title(\"Former\")\n\n@labeled predict_title(\"hjsiunx\")\n\n@labeled predict_title(\"Sturges closed his eyes and let out a deep sigh before responding.\")\n\n@labeled predict_title(\"\"\"Sturges gave a curt nod, before pointing his wand at the stone. Under his command, it rose into the air, made a loop and fell back to the ground.\n\n\"It worked,\" the Auror said, as if he couldn't believe it.\n\nHarry snorted.\"\"\")\n\n@labeled predict_title(\"\"\"\"I'm not a Healer, I wouldn't know,\" the Auror evasively replied. \"Besides, what does it matter now? The boat's gone, Azkaban is sinking, and we're standing around talking.\"\n\n\"It's important because there might be someone else loose on this island! If they found Personal Effects, then they're armed too.\"\n\nSturges froze for a moment, becoming a statue, before shaking his head.\n\n\"Shite, you've got a point - I can't say you're wrong. Bollocks, it's possible. I did a sweep around the Abyss, looking for others, but that doesn't mean I found them all.\" \"\"\")\n\n@labeled predict_title(\"\"\"\nAs a way to light one's path, there was no finer spell than the Thief's Guide. It was a conjured light invisible to others, but it came with a price. The spell took almost thirty seconds to form, and required the same amount of time to wind down, before any other magic would channel through the wand.\n\nHe moved to within a foot of the high cliff face. Dolohov had the high ground, providing an eagle eye view of the island and Harry hoped to hide by sticking close to the rocky terrain. He flew along the shore, traveling in a counter-clockwise trajectory around the island, towards the north side.\n\nFrom behind him a bright light flashed, bathing everything in harsh white light. Harry started to bring his wand up, before the jagged roar of a thunderclap echoed through the air, so close it rattled his teeth within their sockets, filling his skull with ringing pain. Agony ripped through his head as he rose upward, until the overhang atop the walls of the Abyss stretched overhead, providing temporary reprieve from the storm.\n\"\"\")\nnothing"]},{"cell_type":"markdown","metadata":{},"source":["##### \\_\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"| (:luminary) | Float32 | (0.8097029) |"}],"source":["predict_title(\"\"\"Death Eaters aren't worth the regard you'd show a cockroach. The things they've done… they're not even human anymore. They all deserve to suffer, to live every moment in fear, in agony.\"\"\")"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"| (:elizium) | Float32 | (0.7296372) |"}],"source":["predict_title(\"\"\"\"Death Eaters aren't worth the regard you'd show a cockroach. The things they've done… they're not even human anymore. They all deserve to suffer, to live every moment in fear, in agony.\"\n\nThe Auror opened his eyes, keeping his gaze level as he continued.\n\n\"For most of them, the Dementors do the job. But day after day, when you see that Bolshevik piece of shit sitting in his cell, like he's on a fucking vacation… someone has to balance the scales, Potter.\"\n\"\"\")"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"| (:luminary) | Float32 | (0.7834104) |"}],"source":["predict_title(\"\"\"\"Daphnes aren't worth the regard you'd show a cockroach. The things they've done… they're not even human anymore. They all deserve to suffer, to live every moment in fear, in agony.\"\n\nThe Auror opened his eyes, keeping his gaze level as he continued.\n\n\"For most of them, the Dementors do the job. But day after day, when you see that Bolshevik piece of shit sitting in his cell, like he's on a fucking vacation… someone has to balance the scales, Potter.\"\n\"\"\")"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"| (:luminary) | Float32 | (0.6188742) |"}],"source":["predict_title(\"\"\"\"Death Eaters aren't worth the regard you'd show Daphne. The things they've done… they're not even human anymore. They all deserve to suffer, to live every moment in fear, in agony.\"\n\nThe Auror opened his eyes, keeping his gaze level as he continued.\n\n\"For most of them, the Dementors do the job. But day after day, when you see that Bolshevik piece of shit sitting in his cell, like he's on a fucking vacation… someone has to balance the scales, Potter.\"\n\"\"\")"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"| (:luminary) | Float32 | (0.9481187) |"}],"source":["predict_title(\"\"\"\"Death Eaters aren't worth the regard you'd show a cockroach. The things they've done… they're not even human anymore. They all deserve to suffer, to live every moment in fear, in agony.\"\n\nDaphne opened his eyes, keeping his gaze level as he continued.\n\n\"For most of them, the Dementors do the job. But day after day, when you see that Bolshevik piece of shit sitting in his cell, like he's on a fucking vacation… someone has to balance the scales, Potter.\"\n\"\"\")"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"\"Sturges \"|1 (8): ([:luminary], Float32[0.9084659])\n\"Sturges \"|4 (32): ([:luminary], Float32[0.78637934])\n\"Sturges \"|7 (56): ([:luminary], Float32[0.7511015])\n\"Sturges \"|10 (80): ([:luminary], Float32[0.7167213])\n\"Sturges \"|13 (104): ([:luminary], Float32[0.7197282])\n\"Sturges \"|16 (128): ([:luminary], Float32[0.5586547])\n\"Sturges \"|19 (152): ([:luminary], Float32[0.69433963])\n\"Sturges \"|22 (176): ([:elizium], Float32[0.5284413])\n\"Sturges \"|25 (200): ([:elizium], Float32[0.7057922])\n\"Sturges \"|28 (224): ([:elizium], Float32[0.6231144])\n\"Sturges \"|31 (248): ([:elizium], Float32[0.64291555])\n\"Sturges \"|34 (272): ([:elizium], Float32[0.93219006])\n\"Sturges \"|37 (296): ([:elizium], Float32[0.94266087])\n\"Sturges \"|40 (320): ([:elizium], Float32[0.9496109])\n\"Sturges \"|43 (344): ([:elizium], Float32[0.9398242])\n\"Sturges \"|46 (368): ([:elizium], Float32[0.95951897])\n\"Sturges \"|49 (392): ([:elizium], Float32[0.97920173])\n\"Sturges \"|52 (416): ([:elizium], Float32[0.9904779])\n\"Sturges \"|55 (440): ([:elizium], Float32[0.9872892])\n\"Sturges \"|58 (464): ([:elizium], Float32[0.9981779])\n\"Sturges \"|61 (488): ([:elizium], Float32[0.9985221])\n\"Sturges \"|64 (512): ([:elizium], Float32[0.99998176])\n\"Sturges\"|1 (7): ([:luminary], Float32[0.91894454])\n\"Sturges\"|4 (28): ([:luminary], Float32[0.69747823])\n\"Sturges\"|7 (49): ([:luminary], Float32[0.7664588])\n\"Sturges\"|10 (70): ([:luminary], Float32[0.7631384])\n\"Sturges\"|13 (91): ([:luminary], Float32[0.89710164])\n\"Sturges\"|16 (112): ([:luminary], Float32[0.816814])\n\"Sturges\"|19 (133): ([:luminary], Float32[0.7467115])\n\"Sturges\"|22 (154): ([:luminary], Float32[0.81807005])\n\"Sturges\"|25 (175): ([:luminary], Float32[0.817155])\n\"Sturges\"|28 (196): ([:luminary], Float32[0.87153524])\n\"Sturges\"|31 (217): ([:luminary], Float32[0.837211])\n\"Sturges\"|34 (238): ([:luminary], Float32[0.82632333])\n\"Sturges\"|37 (259): ([:luminary], Float32[0.7658739])\n\"Sturges\"|40 (280): ([:luminary], Float32[0.78688633])\n\"Sturges\"|43 (301): ([:luminary], Float32[0.79343736])\n\"Sturges\"|46 (322): ([:luminary], Float32[0.8122535])\n\"Sturges\"|49 (343): ([:luminary], Float32[0.77966666])\n\"Sturges\"|52 (364): ([:luminary], Float32[0.7658739])\n\"Sturges\"|55 (385): ([:luminary], Float32[0.7658739])\n\"Sturges\"|58 (406): ([:luminary], Float32[0.7280034])\n\"Sturges\"|61 (427): ([:luminary], Float32[0.71619225])\n\"Sturges\"|64 (448): ([:luminary], Float32[0.7658739])\n\"Sturges\"|67 (469): ([:luminary], Float32[0.7926266])\n\"Sturges\"|70 (490): ([:luminary], Float32[0.9476907])\n\"Sturges\"|73 (511): ([:luminary], Float32[0.82291657])\n\"\tSturges\t\"|1 (9): ([:luminary], Float32[0.98466915])\n\"\tSturges\t\"|4 (36): ([:luminary], Float32[0.99738425])\n\"\tSturges\t\"|7 (63): ([:luminary], Float32[0.9153329])\n\"\tSturges\t\"|10 (90): ([:elizium], Float32[0.9438124])\n\"\tSturges\t\"|13 (117): ([:elizium], Float32[0.9999902])\n\"\tSturges\t\"|16 (144): ([:elizium], Float32[1.0])\n\"\tSturges\t\"|19 (171): ([:elizium], Float32[1.0])\n\"\tSturges\t\"|22 (198): ([:elizium], Float32[1.0])\n\"\tSturges\t\"|25 (225): ([:elizium], Float32[1.0])\n\"\tSturges\t\"|28 (252): ([:elizium], Float32[1.0])\n\"\tSturges\t\"|31 (279): ([:elizium], Float32[1.0])\n\"\tSturges\t\"|34 (306): ([:elizium], Float32[1.0])\n\"\tSturges\t\"|37 (333): ([:elizium], Float32[1.0])\n\"\tSturges\t\"|40 (360): ([:elizium], Float32[1.0])\n\"\tSturges\t\"|43 (387): ([:elizium], Float32[1.0])\n\"\tSturges\t\"|46 (414): ([:elizium], Float32[1.0])\n\"\tSturges\t\"|49 (441): ([:elizium], Float32[1.0])\n\"\tSturges\t\"|52 (468): ([:elizium], Float32[1.0])\n\"\tSturges\t\"|55 (495): ([:elizium], Float32[1.0])\n\"\tSturges\t\"|58 (522): ([:elizium], Float32[1.0])\n\"\nSturges\n\"|1 (9): ([:luminary], Float32[0.9837257])\n\"\nSturges\n\"|4 (36): ([:luminary], Float32[0.99785995])\n\"\nSturges\n\"|7 (63): ([:luminary], Float32[0.9215182])\n\"\nSturges\n\"|10 (90): ([:elizium], Float32[0.9145907])\n\"\nSturges\n\"|13 (117): ([:elizium], Float32[0.9999672])\n\"\nSturges\n\"|16 (144): ([:elizium], Float32[1.0])\n\"\nSturges\n\"|19 (171): ([:elizium], Float32[1.0])\n\"\nSturges\n\"|22 (198): ([:elizium], Float32[1.0])\n\"\nSturges\n\"|25 (225): ([:elizium], Float32[1.0])\n\"\nSturges\n\"|28 (252): ([:elizium], Float32[1.0])\n\"\nSturges\n\"|31 (279): ([:elizium], Float32[1.0])\n\"\nSturges\n\"|34 (306): ([:elizium], Float32[1.0])\n\"\nSturges\n\"|37 (333): ([:elizium], Float32[1.0])\n\"\nSturges\n\"|40 (360): ([:elizium], Float32[1.0])\n\"\nSturges\n\"|43 (387): ([:elizium], Float32[1.0])\n\"\nSturges\n\"|46 (414): ([:elizium], Float32[1.0])\n\"\nSturges\n\"|49 (441): ([:elizium], Float32[1.0])\n\"\nSturges\n\"|52 (468): ([:elizium], Float32[1.0])\n\"\nSturges\n\"|55 (495): ([:elizium], Float32[1.0])\n\"\nSturges\n\"|58 (522): ([:elizium], Float32[1.0])\n\"Daphne \"|1 (7): ([:luminary], Float32[0.8615514])\n\"Daphne \"|4 (28): ([:luminary], Float32[0.57944894])\n\"Daphne \"|7 (49): ([:elizium], Float32[0.5802219])\n\"Daphne \"|10 (70): ([:elizium], Float32[0.7709762])\n\"Daphne \"|13 (91): ([:elizium], Float32[0.856806])\n\"Daphne \"|16 (112): ([:elizium], Float32[0.8962437])\n\"Daphne \"|19 (133): ([:elizium], Float32[0.9360701])\n\"Daphne \"|22 (154): ([:elizium], Float32[0.9451292])\n\"Daphne \"|25 (175): ([:elizium], Float32[0.9580155])\n\"Daphne \"|28 (196): ([:elizium], Float32[0.97587323])\n\"Daphne \"|31 (217): ([:elizium], Float32[0.9858964])\n\"Daphne \"|34 (238): ([:elizium], Float32[0.99068415])\n\"Daphne \"|37 (259): ([:elizium], Float32[0.9954436])\n\"Daphne \"|40 (280): ([:elizium], Float32[0.99323386])\n\"Daphne \"|43 (301): ([:elizium], Float32[0.99595743])\n\"Daphne \"|46 (322): ([:elizium], Float32[0.997063])\n\"Daphne \"|49 (343): ([:elizium], Float32[0.996554])\n\"Daphne \"|52 (364): ([:elizium], Float32[0.9976845])\n\"Daphne \"|55 (385): ([:elizium], Float32[0.9985098])\n\"Daphne \"|58 (406): ([:elizium], Float32[0.9980161])\n\"Daphne \"|61 (427): ([:elizium], Float32[0.9989992])\n\"Daphne \"|64 (448): ([:elizium], Float32[0.9989015])\n\"Daphne \"|67 (469): ([:elizium], Float32[0.99903274])\n\"Daphne \"|70 (490): ([:elizium], Float32[0.9989741])\n\"Daphne \"|73 (511): ([:elizium], Float32[0.99969304])\n\"Daphne\"|1 (6): ([:luminary], Float32[0.8800906])\n\"Daphne\"|4 (24): ([:luminary], Float32[0.80955136])\n\"Daphne\"|7 (42): ([:luminary], Float32[0.87359834])\n\"Daphne\"|10 (60): ([:luminary], Float32[0.7579535])\n\"Daphne\"|13 (78): ([:luminary], Float32[0.71352124])\n\"Daphne\"|16 (96): ([:luminary], Float32[0.66352475])\n\"Daphne\"|19 (114): ([:luminary], Float32[0.7255676])\n\"Daphne\"|22 (132): ([:luminary], Float32[0.79945016])\n\"Daphne\"|25 (150): ([:luminary], Float32[0.7297182])\n\"Daphne\"|28 (168): ([:luminary], Float32[0.8448794])\n\"Daphne\"|31 (186): ([:luminary], Float32[0.8565506])\n\"Daphne\"|34 (204): ([:luminary], Float32[0.8138204])\n\"Daphne\"|37 (222): ([:luminary], Float32[0.8336204])\n\"Daphne\"|40 (240): ([:luminary], Float32[0.82503927])\n\"Daphne\"|43 (258): ([:luminary], Float32[0.8094206])\n\"Daphne\"|46 (276): ([:luminary], Float32[0.90847826])\n\"Daphne\"|49 (294): ([:luminary], Float32[0.77766144])\n\"Daphne\"|52 (312): ([:luminary], Float32[0.8013817])\n\"Daphne\"|55 (330): ([:luminary], Float32[0.82758427])\n\"Daphne\"|58 (348): ([:luminary], Float32[0.82149667])\n\"Daphne\"|61 (366): ([:luminary], Float32[0.67405784])\n\"Daphne\"|64 (384): ([:luminary], Float32[0.7831406])\n\"Daphne\"|67 (402): ([:luminary], Float32[0.7658739])\n\"Daphne\"|70 (420): ([:luminary], Float32[0.7658739])\n\"Daphne\"|73 (438): ([:luminary], Float32[0.7658739])\n\"Daphne\"|76 (456): ([:luminary], Float32[0.80686116])\n\"Daphne\"|79 (474): ([:luminary], Float32[0.7658739])\n\"Daphne\"|82 (492): ([:luminary], Float32[0.99999803])\n\"Daphne\"|85 (510): ([:luminary], Float32[0.82291657])\n\"Harry \"|1 (6): ([:luminary], Float32[0.90520597])\n\"Harry \"|4 (24): ([:luminary], Float32[0.8497299])\n\"Harry \"|7 (42): ([:luminary], Float32[0.9232881])\n\"Harry \"|10 (60): ([:luminary], Float32[0.899124])\n\"Harry \"|13 (78): ([:luminary], Float32[0.9456601])\n\"Harry \"|16 (96): ([:luminary], Float32[0.97567326])\n\"Harry \"|19 (114): ([:luminary], Float32[0.9579711])\n\"Harry \"|22 (132): ([:luminary], Float32[0.98196566])\n\"Harry \"|25 (150): ([:luminary], Float32[0.9895813])\n\"Harry \"|28 (168): ([:luminary], Float32[0.98945683])\n\"Harry \"|31 (186): ([:luminary], Float32[0.99331117])\n\"Harry \"|34 (204): ([:luminary], Float32[0.9968096])\n\"Harry \"|37 (222): ([:luminary], Float32[0.9982335])\n\"Harry \"|40 (240): ([:luminary], Float32[0.9980396])\n\"Harry \"|43 (258): ([:luminary], Float32[0.99790424])\n\"Harry \"|46 (276): ([:luminary], Float32[0.9982446])\n\"Harry \"|49 (294): ([:luminary], Float32[0.9992256])\n\"Harry \"|52 (312): ([:luminary], Float32[0.9994071])\n\"Harry \"|55 (330): ([:luminary], Float32[0.9998256])\n\"Harry \"|58 (348): ([:luminary], Float32[0.99977195])\n\"Harry \"|61 (366): ([:luminary], Float32[0.9998938])\n\"Harry \"|64 (384): ([:luminary], Float32[0.9998329])\n\"Harry \"|67 (402): ([:luminary], Float32[0.99977374])\n\"Harry \"|70 (420): ([:luminary], Float32[0.99994034])\n\"Harry \"|73 (438): ([:luminary], Float32[0.99977124])\n\"Harry \"|76 (456): ([:luminary], Float32[0.9998982])\n\"Harry \"|79 (474): ([:luminary], Float32[0.99990094])\n\"Harry \"|82 (492): ([:luminary], Float32[0.9999482])\n\"Harry \"|85 (510): ([:luminary], Float32[0.99983907])\n\"Harry Potter \"|1 (13): ([:luminary], Float32[0.82890207])\n\"Harry Potter \"|4 (52): ([:luminary], Float32[0.8515082])\n\"Harry Potter \"|7 (91): ([:luminary], Float32[0.93710357])\n\"Harry Potter \"|10 (130): ([:luminary], Float32[0.91286415])\n\"Harry Potter \"|13 (169): ([:luminary], Float32[0.92091745])\n\"Harry Potter \"|16 (208): ([:luminary], Float32[0.9332891])\n\"Harry Potter \"|19 (247): ([:luminary], Float32[0.96434355])\n\"Harry Potter \"|22 (286): ([:luminary], Float32[0.9825712])\n\"Harry Potter \"|25 (325): ([:luminary], Float32[0.99254185])\n\"Harry Potter \"|28 (364): ([:luminary], Float32[0.99375033])\n\"Harry Potter \"|31 (403): ([:luminary], Float32[0.9981972])\n\"Harry Potter \"|34 (442): ([:luminary], Float32[0.9988368])\n\"Harry Potter \"|37 (481): ([:luminary], Float32[0.9984812])\n\"Harry Potter \"|40 (520): ([:luminary], Float32[0.9716197])\n\"former death eater \"|1 (19): ([:luminary], Float32[0.89179957])\n\"former death eater \"|4 (76): ([:luminary], Float32[0.87866825])\n\"former death eater \"|7 (133): ([:luminary], Float32[0.79445416])\n\"former death eater \"|10 (190): ([:luminary], Float32[0.84965074])\n\"former death eater \"|13 (247): ([:luminary], Float32[0.85968727])\n\"former death eater \"|16 (304): ([:luminary], Float32[0.8823935])\n\"former death eater \"|19 (361): ([:luminary], Float32[0.9766743])\n\"former death eater \"|22 (418): ([:luminary], Float32[0.955864])\n\"former death eater \"|25 (475): ([:luminary], Float32[0.9771394])\n\"former death eater \"|28 (532): ([:luminary], Float32[0.9284054])\n\"former Death Eater \"|1 (19): ([:luminary], Float32[0.89483047])\n\"former Death Eater \"|4 (76): ([:luminary], Float32[0.91536283])\n\"former Death Eater \"|7 (133): ([:luminary], Float32[0.59517527])\n\"former Death Eater \"|10 (190): ([:luminary], Float32[0.6829245])\n\"former Death Eater \"|13 (247): ([:luminary], Float32[0.6325604])\n\"former Death Eater \"|16 (304): ([:luminary], Float32[0.78703505])\n\"former Death Eater \"|19 (361): ([:luminary], Float32[0.8949729])\n\"former Death Eater \"|22 (418): ([:luminary], Float32[0.89971715])\n\"former Death Eater \"|25 (475): ([:luminary], Float32[0.9180496])\n\"former Death Eater \"|28 (532): ([:elizium], Float32[0.5988412])\n\"former Death Eater\"|1 (18): ([:luminary], Float32[0.86180055])\n\"former Death Eater\"|4 (72): ([:luminary], Float32[0.7002988])\n\"former Death Eater\"|7 (126): ([:luminary], Float32[0.59264016])\n\"former Death Eater\"|10 (180): ([:luminary], Float32[0.60319144])\n\"former Death Eater\"|13 (234): ([:luminary], Float32[0.6880965])\n\"former Death Eater\"|16 (288): ([:luminary], Float32[0.66495836])\n\"former Death Eater\"|19 (342): ([:luminary], Float32[0.7718569])\n\"former Death Eater\"|22 (396): ([:luminary], Float32[0.86179024])\n\"former Death Eater\"|25 (450): ([:luminary], Float32[0.708271])\n\"former Death Eater\"|28 (504): ([:elizium], Float32[0.8494184])"}],"source":["for s in (\"Sturges \", \"Sturges\", \"\\tSturges\\t\", \"\\nSturges\\n\", \"Daphne \", \"Daphne\", \"Harry \", \"Harry Potter \", \"former death eater \", \"former Death Eater \", \"former Death Eater\")\n    for i in 1:3:1000\n        sr = repeat(s, i)\n        sr_len = length(codeunits(sr))\n        println(\"\\\"$(s)\\\"|$(i) ($(sr_len)): $(predict_title(sr))\")\n\n        if sr_len >= 500\n            break\n        end\n    end\nend"]},{"cell_type":"markdown","metadata":{},"source":["#### \\_\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"/usr/bin/env: invalid option -- 'S'\nTry '/usr/bin/env --help' for more information."}],"source":["bella(:mbp)"]}],"metadata":[["org"],null,null],"nbformat":4,"nbformat_minor":0}
